[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "resources",
    "section": "",
    "text": "this is a h1 element\n\n\nthis is a h1 element with the title class\n\n\nthis paragraph is organge\n\n\nthis text is centered\n\n\nthis text is centered\n\n\nHere’s where I’m describe something fun I enjoy doing\nher’s a full line\n\nline here.\nline here."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Here is what u do professionally!"
  },
  {
    "objectID": "about.html#what-i-do-for-work",
    "href": "about.html#what-i-do-for-work",
    "title": "About",
    "section": "",
    "text": "Here is what u do professionally!"
  },
  {
    "objectID": "about.html#what-i-do-for-fun",
    "href": "about.html#what-i-do-for-fun",
    "title": "About",
    "section": "What I do for fun",
    "text": "What I do for fun\nGive the people what they want!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Austin Martinez",
    "section": "",
    "text": "What’s up! My name is Austin Martinez (He/Him). I’m currently a graduate student pursuing a Masters of Environmental Data Science at UC Santa Barbara. I am an aspiring GIS analyst and data scientist. I am passionate about applying my background in GIS, machine learning, and predictive modeling to tackle interdisciplinary problems at the intersection of data and decision-making, while also making complex data accessible to everyone, regardless of educational or cultural background. When I’m not coding you can find me at the nearest fishable body of water trying to catch myself a big one."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Biodiversity Intactness Index change in Phoenix, AZ\n\n\n\nPython\n\n\n\nThis analysis maps and quantifies areas in Phoenix, Arizona where high Biodiversity Intactness Index (BII ≥ 0.75) declined between 2017 and 2020.\n\n\n\nAustin Martinez\n\n\nDec 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Suitible Aquaculture Area\n\n\n\nR\n\n\n\nCreating a function that shows you which Exclusive Economic Zones along the U.S. West Coast have the most potential for developing marine aquaculture\n\n\n\nAustin Martinez\n\n\nDec 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nChloride Contamination Analysis\n\n\n\nR\n\n\n\nIdentifying drivers of lake contamination by chloride in the Midwest and Northeast United States\n\n\n\nAustin Martinez\n\n\nDec 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEaton and Palisades Fires analysis\n\n\n\nPython\n\n\n\nThis analysis combines census data, fire perimeters, and Landsat imagery to compare the Eaton and Palisades fires and visualize their burn patterns and surrounding community…\n\n\n\nAustin Martinez\n\n\nDec 3, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html",
    "title": "Eaton and Palisades Fires analysis",
    "section": "",
    "text": "The first part of this project focused on visualizing the extent of the Palisades and Eaton fires and how socioeconomic factors, like the percentage of unemployed residents, may shape a community’s ability to respond to a wildfire. The second part of this project was to use false-color Landsat 8 imagery to visualize the extent of Palisades and Eaton fire perimeters around the LA County area. False-color was used to enhance burn severity and vegetation patterns in the background image. The false-color composite was made up of SWIR, NIR, and Red bands.\n\n\n\n\n\n\nReprojected the CRS of Eaton and Palisades shapefiles to match the EJI’s CRS.\nUsed geopandas.sjoin() to identify EJI census tracts intersecting each fire perimeter\nUsed clipping to clip the census tracts within the fire perimeters\nVisualized unemployment levels in both fire perimeters to see if it could influence a community’s response to a wildfire\n\n\n\n\n\nCreated a false-color image using using SWIR, NIR, and Red bands from the Landsat 8 raster.\nReprojected the CRS of Eaton and Palisades shapefiles to match the Landsat 8 raster’s CRS.\nReplaced NaNs in the Landsat 8 raster’s bands with 0s.\nPlotted the Eaton and Palisades perimeters onto the false-color image.\nVisualized unemployment levels (E_UNEMP) for both fire areas\n\n\n\n\n\n\nEaton_Perimeter_20250121.shp: Dissolved fire perimeter/boundary of the Eaton Fire that took place during January 2025. It was collected by the NIFC FIRIS program.\nPalisades_Perimeter_20250121.shp: Dissolved fire perimeter/boundary of the Palisades Fire that took place during January 2025. It was collected by the NIFC FIRIS program.\nlandsat8-2025-02-23-palisades-eaton.nc: This dataset is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmospherically corrected surface reflectance data, collected by the Landsat 8 satellite.\nEJI_2024_United_States.gdb: This Geodatabase contains 2024 Environmental Justice Index (EJI) data for the United States. This includes census-tract–level indicators, component scores, and overall EJI scores derived from environmental, health, and socioeconomic variables. It was collected by the CDC/ATSDR, in partnership with the U.S. Census Bureau.\n\n\n\n\n\n\nCounty of Los Angeles. (2025). Palisades and Eaton dissolved fire perimeters (2025) [Feature layer]. ArcGIS Hub. https://services1.arcgis.com/jUJYIo9tSA7EHvfZ/ArcGIS/rest/services/CA_Perimeters_NIFC_FIRIS_public_view/FeatureServer. [Accessed Nov. 20, 2025]\n\n\nU.S. Geological Survey. (2025). Landsat Collection 2 Level-2 surface reflectance (red, green, blue, near-infrared, shortwave infrared) for Eaton and Palisades fires, Los Angeles County, CA [NetCDF dataset]. Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/. [Accessed Nov. 20, 2025]\n\n\nCenters for Disease Control and Prevention & Agency for Toxic Substances and Disease Registry. (2024). Environmental Justice Index 2024: United States geodatabase [Data set]. GRASP Program. https://atsdr.cdc.gov/place-health/php/eji/eji-data-download.html [Accessed Nov. 20, 2025]\n\n\n\n\n\nIn the code 3 code chunks are for importing the libraries necessary for running this notebook. Reproducible file path were created using os, these file path were used to read in the shapefiles, geodatabase, and raster. The 4 datasets were named Eaton(Eaton shapefile), Palisades(Palisades shapefile), EJI(EJI geodatabase), and Landsat_8(Landsat 8 raster).\n\n# Load in Libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rio\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\n# Create a reproducible file path\nEaton_fp = os.path.join('data','Eaton_Perimeter_20250121','Eaton_Perimeter_20250121.shp')\nPalisades_fp = os.path.join('data','Palisades_Perimeter_20250121','Palisades_Perimeter_20250121.shp')\nEJ_fp = os.path.join(\"data\", \"EJI_2024_United_States\", \"EJI_2024_United_States.gdb\")\nNC_fp = os.path.join('data','landsat8-2025-02-23-palisades-eaton.nc')\n\n\n# Read in data\nEaton = gpd.read_file(Eaton_fp)\nPalisades = gpd.read_file(Palisades_fp)\nEJI = gpd.read_file(EJ_fp)\nLandsat_8 = xr.open_dataset(NC_fp)\n\n\n\n\n\n\n\nI selected a variable that, in my opinion, could influence a community’s response to a wildfire from EJI. - E_UNEMP - Percentage of persons who are unemployed\n\n\n\nThe next 3 code chunks are used to spatially join the EJI data with the Palisades fire perimeter using geopandas.sjoin() to get a geopandas.GeoDataFrame that will have only have the census tracts intersecting the Palisades fire perimeter.\n\n# Transform the CRS of Palisades to match the CRS of EJI\nPalisades = Palisades.to_crs(EJI.crs)\n\n# Verify CRSs match \nprint(f\" Palisades and EJI CRSs match: {Palisades.crs == EJI.crs}\")\n\n Palisades and EJI CRSs match: True\n\n\n\n# Spatially join the EJI data with the Palisades fire perimeter\nPE_data = gpd.sjoin(EJI, Palisades)\n\n\n# Plot the census tracts that intersect the Palisades fire perimeter\nfig, ax = plt.subplots()\nPE_data.plot(ax=ax, color='green')\nPalisades.plot(ax=ax, color = \"red\")\nfig.suptitle('Palisades Fire Perimeter Over Census Tracts')\nax.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nThe next 3 code chunks are used to spatially join the EJI data with the Eaton fire perimeter using geopandas.sjoin() to get a geopandas.GeoDataFrame that will have only have the census tracts intersecting the Eaton fire perimeter.\n\n# Transform the CRS of Eaton to match the CRS of EJI\nEaton = Eaton.to_crs(EJI.crs)\n\n# Verify CRSs match \nprint(f\" Eaton and EJI CRSs match: {Eaton.crs == EJI.crs}\")\n\n Eaton and EJI CRSs match: True\n\n\n\n# Spatially join the EJI data with the Palisades fire perimeter\nEE_data = gpd.sjoin(EJI, Eaton)\n\n\n# Plot the census tracts that intersect the Eaton fire perimeter\nfig, ax = plt.subplots()\nEE_data.plot(ax=ax, color='green')\nEaton.plot(ax=ax, color = \"red\")\nfig.suptitle('Eaton Fire Over Census Tracts')\nax.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe next 2 code chunks are used to clip the census tracts to the Palisades and Eaton Fires perimeter using geopandas.clip(). The clipped census tracts(Palisades_fire, Eaton_fire) were then plotted ontop of the fires perimeters to show they are the same shape.\n\n# Clip the census tracts to the Palisades and Eaton Fires perimeter\nEaton_fire = gpd.clip(EE_data, Eaton)\nPalisades_fire = gpd.clip(PE_data, Palisades)\n\n\n# Plot the clipped census tracts over the fires perimeters to show they are the same shape\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 6))\n\n# Palisades fire perimeter\nPalisades_fire.plot(ax=ax1, color='red')\nPalisades.plot(ax=ax1, color='blue')\nax1.set_title('Palisades Fire')\nax1.axis('off')\n\n# Eaton fire perimeter\nEaton_fire.plot(ax=ax2, color='red')\nEaton.plot(ax=ax2, color='blue')\nax2.set_title('Eaton Fire')\nax2.axis('off')\n\n# Add title\nfig.suptitle('Fire Perimeter Comparison')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to visualize fire perimeters with a basemap. This was done by adding a basemap to the plot using the contextily library.\n\n# Plot the fire perimeters with a basemap\nfig, ax = plt.subplots(1, 1, figsize=(9, 12))\n\n# Eaton fire perimeter\nEaton_fire.plot(ax=ax, color='red', alpha=0.7, label='Eaton Fire')\n\n# Palisades fire perimeter\nPalisades_fire.plot(ax=ax, color='blue', alpha=0.8, label='Palisades Fire')\n\n# Add a basemap\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik,crs=Palisades_fire.crs)\n\n# Add title\nax.set_title(\"Comparison of Eaton and Palisades Fire Perimeters\", fontsize=16)\n\n# Add labels with gray background\nplt.figtext(0.10, 0.53, \"Palisades Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.85, 0.46, \"Eaton Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axis\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below was used to plot a given variable(E_UNEMP)that was relevant to a community’s response to a wildfire.\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n\n# Insert EJI variable to visualize\neji_variable = 'E_UNEMP'\n\n# Find common min/max for legend range\nvmin = min(Palisades_fire[eji_variable].min(), Eaton_fire[eji_variable].min())\nvmax = max(Palisades_fire[eji_variable].max(), Eaton_fire[eji_variable].max())\n\n# Plot census tracts within Palisades perimeter\nPalisades_fire.plot(\n    column= eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax1,\n)\nax1.set_title('Palisades', fontsize=18)\nax1.axis('off')\n\n# Plot census tracts within Eaton perimeter\nEaton_fire.plot(\n    column=eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax2,\n)\nax2.set_title('Eaton', fontsize=18)\nax2.axis('off')\n\n# Add overall title\nfig.suptitle('Percentage of Persons Who are Unemployed - Fire Areas Comparison', fontsize=18)\n\n# Add shared colorbar at the bottom\nsm = plt.cm.ScalarMappable( norm=plt.Normalize(vmin=vmin, vmax=vmax))\ncbar_ax = fig.add_axes([0.25, 0.08, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Percent Unemployment (%)')\n\n# Display the map\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Check if data are projected or geographic\nprint(f\"The CRS of Eaton is projected: {Eaton.crs.is_projected}\")\nprint(f\"The CRS of Palisades is projected: {Palisades.crs.is_projected}\", \"\\n\")\n\n# Verify CRSs match \nprint(f\" Palisades and Eaton columns match: {Palisades.columns == Eaton.columns}\")\n\nThe CRS of Eaton is projected: True\nThe CRS of Palisades is projected: True \n\n Palisades and Eaton columns match: [ True  True  True  True  True]\n\n\n\n\n\nThe 5 code chunks below are used to clean the data, so that a true color image can be created from landsat_8. In the code chunk below, the crs for Landsat_8 is stored in the spatial_ref variable. To recover the geospatial information from it rio.write_crs() was used. rio.crs can now be used to access the CRS of landsat_8.\n\n# Print the CRS by using the spatial_ref.crs_wkt attribute\nprint(f\"Landsat_8 CRS: {Landsat_8.spatial_ref.crs_wkt}\",\"\\n\")\n\n# Recover the geospatial information by using rio.write_crs()\nLandsat_8.rio.write_crs(Landsat_8.spatial_ref.crs_wkt, inplace=True)\n\n# Print the CRS of the updated dataset\nprint(\"Updated CRS:\", Landsat_8.rio.crs)\n\nLandsat_8 CRS: PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]] \n\nUpdated CRS: EPSG:32611\n\n\n\n\n\n\n\nIn the code chunk below, the red, green, and blue variables (in that order) of the xarray.Dataset were selected and were converted to an array using the to_array() method. The array was then plotted using .plot.imshow() to create an RGB image with the data. Unfortunately, no image was produced because of the clouds: their RGB values are outliers and cause the other values to be squished when plotting. The parameter robust=True was used to adjust the scale used for plotting the bands to get a true color image.\n\n# Select the red, green, and blue variables of the xarray.Dataset holding the Landsat data\n# Use .plot.imshow() to create an RGB image with the data\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n/Users/austinmartinez/opt/anaconda3/envs/eds220-env/lib/python3.11/site-packages/matplotlib/cm.py:478: RuntimeWarning: invalid value encountered in cast\n  xx = (xx * 255).astype(np.uint8)\n\n\n\n\n\n\n\n\n\nIn the nect 2 code chunks below, to resolve the warning the bands with nan values were identified using a for loop and .fillna() was used to replace the nan values with 0s. The bands blue and green had nans. Once, the nans were replaced with 0s the warning was resolved.\n\n# Select \"red\", \"green\", \"blue\" bands\nbands = [\"red\", \"green\", \"blue\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\nred contains NaN values? False\ngreen contains NaN values? True\nblue contains NaN values? True\n\n\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"green\", \"blue\"]] = Landsat_8[[\"green\", \"blue\"]].fillna(0)\n\n# Plot RGB raster\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below created a false-color image by using the “swir22”, “nir08”, and “red” bands. This was plotted using the same method used with the true color image.\n\n# Use .plot.imshow() to create a false color image with the data\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the CRS of Eaton and Palisades was reprojected to match the Landsat_8 CRS. This was done so we can plot the Eaton and Palisades perimeters onto the false-color image. A for loop was then used to identify that the “swir22”, “nir08” had nan values. To resolve this .fillna(0) was used to replace the nan values with 0s.\n\n# Change the CRS of Palisades and Eaton to match Landsat_8\nPalisades = Palisades.to_crs(Landsat_8.rio.crs)\nEaton = Eaton.to_crs(Landsat_8.rio.crs)\n\n# Verify the CRS of Palisades and Eaton to match Landsat_8\nprint(f\" Palisades and Landsat_8 CRSs match: {Palisades.crs == Landsat_8.rio.crs}\")\nprint(f\" Eaton and Landsat_8 CRSs match: {Eaton.crs == Landsat_8.rio.crs}\", \"\\n\")\n\n# Select \"swir22\", \"nir08\" bands\nbands = [\"swir22\", \"nir08\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"swir22\", \"nir08\"]] = Landsat_8[[\"swir22\", \"nir08\"]].fillna(0)\n\n Palisades and Landsat_8 CRSs match: True\n Eaton and Landsat_8 CRSs match: True \n\nswir22 contains NaN values? False\nnir08 contains NaN values? False\n\n\nThe code chunk below is used to plot the Eaton and Palisades perimeters onto the false-color image.\n\n# Create figure\nfig, ax = plt.subplots(1, 1, figsize=(9, 6))\n\n# Add Palisades and Eaton fire perimeters\nPalisades.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\nEaton.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2,legend=True)\n\n# Add false color raster\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n# Add title\nax.set_title('False Color (SWIR–NIR–Red) Map of the Palisades and Eaton Fire Perimeters')\n\n## # Add annotation describing the false color\nplt.annotate(\n    'Background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands.',\n    xy=(0.15, 0.04),\n    xycoords='figure fraction',\n    fontsize=9,\n    color='gray'\n)\n\n# Add labels with gray background\nplt.figtext(0.13, 0.47, \"Palisades Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.72, 0.77, \"Eaton Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe map above shows a false color image of the LA County area, displaying the perimeter of fires that occured in the Palisades(in red) and Eaton(in blue). False color imagery is being used in the background image. The background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands. These bands are used to enhance burn severity and vegetation patterns. The false colors in this background image show healthy vegetation as bright green, urban areas as cyan/gray, and burnt area areas as a reddish brown.\n\n(Los Angeles 2025)\n(Survey 2025)\n(Disease Control et al. 2024)"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#about-section",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#about-section",
    "title": "Eaton and Palisades Fires Analysis and Accompanying Analyses",
    "section": "About Section",
    "text": "About Section\n\nPurpose:\nThe first part of this project focused on visualizing the extent of the Palisades and Eaton fires and how socioeconomic factors, like the percentage of unemployed residents, may shape a community’s ability to respond to a wildfire. The second part of this project was to use false-color Landsat 8 imagery to visualize the extent of Palisades and Eaton fire perimeters around the LA County area. False-color was used to enhance burn severity and vegetation patterns in the background image. The false-color composite was made up of SWIR, NIR, and Red bands.\n\n\nHighlights:\n\nSocial dimensions of Eaton and Palisades fires\n\nReprojected the CRS of Eaton and Palisades shapefiles to match the EJI’s CRS.\nUsed geopandas.sjoin() to identify EJI census tracts intersecting each fire perimeter\nUsed clipping to clip the census tracts within the fire perimeters\nVisualized unemployment levels in both fire perimeters to see if it could influence a community’s response to a wildfire\n\n\n\nVisualizing Fire Scares Through False Color\n\nCreated a false-color image using using SWIR, NIR, and Red bands from the Landsat 8 raster.\nReprojected the CRS of Eaton and Palisades shapefiles to match the Landsat 8 raster’s CRS.\nReplaced NaNs in the Landsat 8 raster’s bands with 0s.\nPlotted the Eaton and Palisades perimeters onto the false-color image.\nVisualized unemployment levels (E_UNEMP) for both fire areas\n\n\n\n\nAbout the data:\n\nEaton_Perimeter_20250121.shp: Dissolved fire perimeter/boundary of the Eaton Fire that took place during January 2025. It was collected by the NIFC FIRIS program.\nPalisades_Perimeter_20250121.shp: Dissolved fire perimeter/boundary of the Palisades Fire that took place during January 2025. It was collected by the NIFC FIRIS program.\nlandsat8-2025-02-23-palisades-eaton.nc: This dataset is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmospherically corrected surface reflectance data, collected by the Landsat 8 satellite.\nEJI_2024_United_States.gdb: This Geodatabase contains 2024 Environmental Justice Index (EJI) data for the United States. This includes census-tract–level indicators, component scores, and overall EJI scores derived from environmental, health, and socioeconomic variables. It was collected by the CDC/ATSDR, in partnership with the U.S. Census Bureau.\n\n\n\nReferences:\n\n\nCounty of Los Angeles. (2025). Palisades and Eaton dissolved fire perimeters (2025) [Feature layer]. ArcGIS Hub. https://services1.arcgis.com/jUJYIo9tSA7EHvfZ/ArcGIS/rest/services/CA_Perimeters_NIFC_FIRIS_public_view/FeatureServer. [Accessed Nov. 20, 2025]\n\n\nU.S. Geological Survey. (2025). Landsat Collection 2 Level-2 surface reflectance (red, green, blue, near-infrared, shortwave infrared) for Eaton and Palisades fires, Los Angeles County, CA [NetCDF dataset]. Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/. [Accessed Nov. 20, 2025]\n\n\nCenters for Disease Control and Prevention & Agency for Toxic Substances and Disease Registry. (2024). Environmental Justice Index 2024: United States geodatabase [Data set]. GRASP Program. https://atsdr.cdc.gov/place-health/php/eji/eji-data-download.html [Accessed Nov. 20, 2025]\n\n\n\n\nReading in Data\nIn the code 3 code chunks are for importing the libraries necessary for running this notebook. Reproducible file path were created using os, these file path were used to read in the shapefiles, geodatabase, and raster. The 4 datasets were named Eaton(Eaton shapefile), Palisades(Palisades shapefile), EJI(EJI geodatabase), and Landsat_8(Landsat 8 raster).\n\n# Load in Libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rio\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\n# Create a reproducible file path\nEaton_fp = os.path.join('data','Eaton_Perimeter_20250121','Eaton_Perimeter_20250121.shp')\nPalisades_fp = os.path.join('data','Palisades_Perimeter_20250121','Palisades_Perimeter_20250121.shp')\nEJ_fp = os.path.join(\"data\", \"EJI_2024_United_States\", \"EJI_2024_United_States.gdb\")\nNC_fp = os.path.join('data','landsat8-2025-02-23-palisades-eaton.nc')\n\n\n# Read in data\nEaton = gpd.read_file(Eaton_fp)\nPalisades = gpd.read_file(Palisades_fp)\nEJI = gpd.read_file(EJ_fp)\nLandsat_8 = xr.open_dataset(NC_fp)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[10], line 5\n      3 Palisades = gpd.read_file(Palisades_fp)\n      4 EJI = gpd.read_file(EJ_fp)\n----&gt; 5 Landsat_8 = xr.open_dataset(NC_fp)\n\nFile ~/opt/anaconda3/envs/eds220-env/lib/python3.11/site-packages/xarray/backends/api.py:652, in open_dataset(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\n    649     kwargs.update(backend_kwargs)\n    651 if engine is None:\n--&gt; 652     engine = plugins.guess_engine(filename_or_obj)\n    654 if from_array_kwargs is None:\n    655     from_array_kwargs = {}\n\nFile ~/opt/anaconda3/envs/eds220-env/lib/python3.11/site-packages/xarray/backends/plugins.py:194, in guess_engine(store_spec)\n    186 else:\n    187     error_msg = (\n    188         \"found the following matches with the input file in xarray's IO \"\n    189         f\"backends: {compatible_engines}. But their dependencies may not be installed, see:\\n\"\n    190         \"https://docs.xarray.dev/en/stable/user-guide/io.html \\n\"\n    191         \"https://docs.xarray.dev/en/stable/getting-started-guide/installing.html\"\n    192     )\n--&gt; 194 raise ValueError(error_msg)\n\nValueError: found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#social-dimensions-of-eaton-and-palisades-fires-1",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#social-dimensions-of-eaton-and-palisades-fires-1",
    "title": "Eaton and Palisades Fires Analysis and Accompanying Analyses",
    "section": "Social dimensions of Eaton and Palisades fires",
    "text": "Social dimensions of Eaton and Palisades fires\n\nMetadata exploration\nI selected a variable that, in my opinion, could influence a community’s response to a wildfire from EJI. - E_UNEMP - Percentage of persons who are unemployed\n\n\nPolygon intersection\nThe next 3 code chunks are used to spatially join the EJI data with the Palisades fire perimeter using geopandas.sjoin() to get a geopandas.GeoDataFrame that will have only have the census tracts intersecting the Palisades fire perimeter.\n\n# Transform the CRS of Palisades to match the CRS of EJI\nPalisades = Palisades.to_crs(EJI.crs)\n\n# Verify CRSs match \nprint(f\" Palisades and EJI CRSs match: {Palisades.crs == EJI.crs}\")\n\n Palisades and EJI CRSs match: True\n\n\n\n# Spatially join the EJI data with the Palisades fire perimeter\nPE_data = gpd.sjoin(EJI, Palisades)\n\n\n# Plot the census tracts that intersect the Palisades fire perimeter\nfig, ax = plt.subplots()\nPE_data.plot(ax=ax, color='green')\nPalisades.plot(ax=ax, color = \"red\")\nfig.suptitle('Palisades Fire Perimeter Over Census Tracts')\nax.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nThe next 3 code chunks are used to spatially join the EJI data with the Eaton fire perimeter using geopandas.sjoin() to get a geopandas.GeoDataFrame that will have only have the census tracts intersecting the Eaton fire perimeter.\n\n# Transform the CRS of Eaton to match the CRS of EJI\nEaton = Eaton.to_crs(EJI.crs)\n\n# Verify CRSs match \nprint(f\" Eaton and EJI CRSs match: {Eaton.crs == EJI.crs}\")\n\n Eaton and EJI CRSs match: True\n\n\n\n# Spatially join the EJI data with the Palisades fire perimeter\nEE_data = gpd.sjoin(EJI, Eaton)\n\n\n# Plot the census tracts that intersect the Eaton fire perimeter\nfig, ax = plt.subplots()\nEE_data.plot(ax=ax, color='green')\nEaton.plot(ax=ax, color = \"red\")\nfig.suptitle('Eaton Fire Over Census Tracts')\nax.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPolygon clipping\nThe next 2 code chunks are used to clip the census tracts to the Palisades and Eaton Fires perimeter using geopandas.clip(). The clipped census tracts(Palisades_fire, Eaton_fire) were then plotted ontop of the fires perimeters to show they are the same shape.\n\n# Clip the census tracts to the Palisades and Eaton Fires perimeter\nEaton_fire = gpd.clip(EE_data, Eaton)\nPalisades_fire = gpd.clip(PE_data, Palisades)\n\n\n# Plot the clipped census tracts over the fires perimeters to show they are the same shape\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n\n# Palisades fire perimeter\nPalisades_fire.plot(ax=ax1, color='red')\nPalisades.plot(ax=ax1, color='blue')\nax1.set_title('Palisades Fire')\nax1.axis('off')\n\n# Eaton fire perimeter\nEaton_fire.plot(ax=ax2, color='red')\nEaton.plot(ax=ax2, color='blue')\nax2.set_title('Eaton Fire')\nax2.axis('off')\n\n# Title\nfig.suptitle('Fire Perimeter Comparison')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nVisualize fire perimeters with a basemap\nThe code chunk below is used to visualize fire perimeters with a basemap. This was done by adding a basemap to the plot using the contextily library.\n\n# Plot the fire perimeters with a basemap\nfig, ax = plt.subplots(1, 1, figsize=(10, 12))\n\n# Eaton fire perimeter\nEaton_fire.plot(ax=ax, color='red', alpha=0.7, label='Eaton Fire')\n\n# Palisades fire perimeter\nPalisades_fire.plot(ax=ax, color='blue', alpha=0.8, label='Palisades Fire')\n\n# Add a basemap\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik,crs=Palisades_fire.crs)\n\n# Add title\nax.set_title(\"Comparison of Eaton and Palisades Fire Perimeters\", fontsize=16)\n\n# Add labels with gray background\nplt.figtext(0.10, 0.53, \"Palisades Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.85, 0.46, \"Eaton Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axis\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nVisualize EJI data\nThe code chunk below was used to plot a given variable(E_UNEMP)that was relevant to a community’s response to a wildfire.\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n\n# Insert EJI variable to visualize\neji_variable = 'E_UNEMP'\n\n# Find common min/max for legend range\nvmin = min(Palisades_fire[eji_variable].min(), Eaton_fire[eji_variable].min())\nvmax = max(Palisades_fire[eji_variable].max(), Eaton_fire[eji_variable].max())\n\n# Plot census tracts within Palisades perimeter\nPalisades_fire.plot(\n    column= eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax1,\n)\nax1.set_title('Palisades', fontsize=20)\nax1.axis('off')\n\n# Plot census tracts within Eaton perimeter\nEaton_fire.plot(\n    column=eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax2,\n)\nax2.set_title('Eaton', fontsize=20)\nax2.axis('off')\n\n# Add overall title\nfig.suptitle('Percentage of Persons Who are Unemployed - Fire Areas Comparison', fontsize=20)\n\n# Add shared colorbar at the bottom\nsm = plt.cm.ScalarMappable( norm=plt.Normalize(vmin=vmin, vmax=vmax))\ncbar_ax = fig.add_axes([0.25, 0.08, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Percent Unemployment (%)')\n\n# Display the map\nplt.show()"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#visualize-fire-perimeters-with-a-basemap",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#visualize-fire-perimeters-with-a-basemap",
    "title": "Eaton and Palisades Fires Analysis and Accompanying Analyses",
    "section": "Visualize fire perimeters with a basemap",
    "text": "Visualize fire perimeters with a basemap\nThe code chunk below is used to visualize fire perimeters with a basemap. This was done by adding a basemap to the plot using the contextily library.\n\n# Plot the fire perimeters with a basemap\nfig, ax = plt.subplots(1, 1, figsize=(10, 12))\n\n# Eaton fire perimeter\nEaton_fire.plot(ax=ax, color='red', alpha=0.7, label='Eaton Fire')\n\n# Palisades fire perimeter\nPalisades_fire.plot(ax=ax, color='blue', alpha=0.8, label='Palisades Fire')\n\n# Add a basemap\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik,crs=Palisades_fire.crs)\n\n# Add title\nax.set_title(\"Comparison of Eaton and Palisades Fire Perimeters\", fontsize=16)\n\n# Add labels with gray background\nplt.figtext(0.10, 0.53, \"Palisades Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.85, 0.46, \"Eaton Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axis\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#visualize-eji-data",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#visualize-eji-data",
    "title": "Eaton and Palisades Fires Analysis and Accompanying Analyses",
    "section": "Visualize EJI data",
    "text": "Visualize EJI data\nThe code chunk below was used to plot a given variable(E_UNEMP)that was relevant to a community’s response to a wildfire.\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n\n# Insert EJI variable to visualize\neji_variable = 'E_UNEMP'\n\n# Find common min/max for legend range\nvmin = min(Palisades_fire[eji_variable].min(), Eaton_fire[eji_variable].min())\nvmax = max(Palisades_fire[eji_variable].max(), Eaton_fire[eji_variable].max())\n\n# Plot census tracts within Palisades perimeter\nPalisades_fire.plot(\n    column= eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax1,\n)\nax1.set_title('Palisades', fontsize=20)\nax1.axis('off')\n\n# Plot census tracts within Eaton perimeter\nEaton_fire.plot(\n    column=eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax2,\n)\nax2.set_title('Eaton', fontsize=20)\nax2.axis('off')\n\n# Add overall title\nfig.suptitle('Percentage of Persons Who are Unemployed - Fire Areas Comparison', fontsize=20)\n\n# Add shared colorbar at the bottom\nsm = plt.cm.ScalarMappable( norm=plt.Normalize(vmin=vmin, vmax=vmax))\ncbar_ax = fig.add_axes([0.25, 0.08, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Percent Unemployment (%)')\n\n# Display the map\nplt.show()"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#visualizing-fire-scares-through-false-color-1",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#visualizing-fire-scares-through-false-color-1",
    "title": "Eaton and Palisades Fires Analysis and Accompanying Analyses",
    "section": "Visualizing Fire Scares Through False Color",
    "text": "Visualizing Fire Scares Through False Color\n\nFire perimeter data exploration\n\n# Check if data are projected or geographic\nprint(f\"The CRS of Eaton is projected: {Eaton.crs.is_projected}\")\nprint(f\"The CRS of Palisades is projected: {Palisades.crs.is_projected}\", \"\\n\")\n\n# Verify CRSs match \nprint(f\" Palisades and Eaton columns match: {Palisades.columns == Eaton.columns}\")\n\nThe CRS of Eaton is projected: True\nThe CRS of Palisades is projected: True \n\n Palisades and Eaton columns match: [ True  True  True  True  True]\n\n\n\n\nRestoring geospatial\nThe 5 code chunks below are used to clean the data, so that a true color image can be created from landsat_8.\nIn the code chunk below, the crs for Landsat_8 is stored in the spatial_ref variable. To recover the geospatial information from it rio.write_crs() was used. rio.crs can now be used to access the CRS of landsat_8.\n\n# Print the CRS by using the spatial_ref.crs_wkt attribute\nprint(f\"Landsat_8 CRS: {Landsat_8.spatial_ref.crs_wkt}\",\"\\n\")\n\n# Recover the geospatial information by using rio.write_crs()\nLandsat_8.rio.write_crs(Landsat_8.spatial_ref.crs_wkt, inplace=True)\n\n# Print the CRS of the updated dataset\nprint(\"Updated CRS:\", Landsat_8.rio.crs)\n\nLandsat_8 CRS: PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]] \n\nUpdated CRS: EPSG:32611\n\n\n\n\nTrue color image\n\nData Cleaning and Visualization - True-color\nIn the code chunk below, the red, green, and blue variables (in that order) of the xarray.Dataset were selected and were converted to an array using the to_array() method. The array was then plotted using .plot.imshow() to create an RGB image with the data. Unfortunately, no image was produced because of the clouds: their RGB values are outliers and cause the other values to be squished when plotting. The parameter robust=True was used to adjust the scale used for plotting the bands to get a true color image.\n\n# Select the red, green, and blue variables of the xarray.Dataset holding the Landsat data\n# Use .plot.imshow() to create an RGB image with the data\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n/opt/anaconda3/envs/eds220-env/lib/python3.11/site-packages/matplotlib/cm.py:478: RuntimeWarning: invalid value encountered in cast\n  xx = (xx * 255).astype(np.uint8)\n\n\n\n\n\n\n\n\n\nIn the nect 2 code chunks below, to resolve the warning the bands with nan values were identified using a for loop and .fillna() was used to replace the nan values with 0s. The bands blue and green had nans. Once, the nans were replaced with 0s the warning was resolved.\n\n# Select \"red\", \"green\", \"blue\" bands\nbands = [\"red\", \"green\", \"blue\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\nred contains NaN values? False\ngreen contains NaN values? True\nblue contains NaN values? True\n\n\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"green\", \"blue\"]] = Landsat_8[[\"green\", \"blue\"]].fillna(0)\n\n# Plot RGB raster\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\nFalse color image\n\nData Cleaning and Visualization - True-color\nThe code chunk below created a false-color image by using the “swir22”, “nir08”, and “red” bands. This was plotted using the same method used with the true color image.\n\n# Use .plot.imshow() to create a false color image with the data\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\nFalse-color map with fire parimeters\nIn the code chunk below, the CRS of Eaton and Palisades was reprojected to match the Landsat_8 CRS. This was done so we can plot the Eaton and Palisades perimeters onto the false-color image. A for loop was then used to identify that the “swir22”, “nir08” had nan values. To resolve this .fillna(0) was used to replace the nan values with 0s.\n\n# Change the CRS of Palisades and Eaton to match Landsat_8\nPalisades = Palisades.to_crs(Landsat_8.rio.crs)\nEaton = Eaton.to_crs(Landsat_8.rio.crs)\n\n# Verify the CRS of Palisades and Eaton to match Landsat_8\nprint(f\" Palisades and Landsat_8 CRSs match: {Palisades.crs == Landsat_8.rio.crs}\")\nprint(f\" Eaton and Landsat_8 CRSs match: {Eaton.crs == Landsat_8.rio.crs}\", \"\\n\")\n\n# Select \"swir22\", \"nir08\" bands\nbands = [\"swir22\", \"nir08\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"swir22\", \"nir08\"]] = Landsat_8[[\"swir22\", \"nir08\"]].fillna(0)\n\n Palisades and Landsat_8 CRSs match: True\n Eaton and Landsat_8 CRSs match: True \n\nswir22 contains NaN values? False\nnir08 contains NaN values? False\n\n\nThe code chunk below is used to plot the Eaton and Palisades perimeters onto the false-color image.\n\n# Create figure\nfig, ax = plt.subplots(1, 1, figsize=(9, 6))\n\n# Add Palisades and Eaton fire perimeters\nPalisades.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\nEaton.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2,legend=True)\n\n# Add false color raster\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n# Add title\nax.set_title('False Color (SWIR–NIR–Red) Map of the Palisades and Eaton Fire Perimeters')\n\n## # Add annotation describing the false color\nplt.annotate(\n    'Background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands.',\n    xy=(0.15, 0.04),\n    xycoords='figure fraction',\n    fontsize=9,\n    color='gray'\n)\n\n# Add labels with gray background\nplt.figtext(0.13, 0.47, \"Palisades Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.72, 0.77, \"Eaton Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nMap Description:\nThe map above shows a false color image of the LA County area, displaying the perimeter of fires that occured in the Palisades(in red) and Eaton(in blue). False color imagery is being used in the background image. The background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands. These bands are used to enhance burn severity and vegetation patterns. The false colors in this background image show healthy vegetation as bright green, urban areas as cyan/gray, and burnt area areas as a reddish brown."
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#true-color-image",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#true-color-image",
    "title": "Eaton and Palisades Fires Analysis and Accompanying Analyses",
    "section": "True color image",
    "text": "True color image\n\nData Cleaning and Visualization - True-color\nIn the code chunk below, the red, green, and blue variables (in that order) of the xarray.Dataset were selected and were converted to an array using the to_array() method. The array was then plotted using .plot.imshow() to create an RGB image with the data. Unfortunately, no image was produced because of the clouds: their RGB values are outliers and cause the other values to be squished when plotting. The parameter robust=True was used to adjust the scale used for plotting the bands to get a true color image.\n\n# Select the red, green, and blue variables of the xarray.Dataset holding the Landsat data\n# Use .plot.imshow() to create an RGB image with the data\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n/opt/anaconda3/envs/eds220-env/lib/python3.11/site-packages/matplotlib/cm.py:478: RuntimeWarning: invalid value encountered in cast\n  xx = (xx * 255).astype(np.uint8)\n\n\n\n\n\n\n\n\n\nIn the nect 2 code chunks below, to resolve the warning the bands with nan values were identified using a for loop and .fillna() was used to replace the nan values with 0s. The bands blue and green had nans. Once, the nans were replaced with 0s the warning was resolved.\n\n# Select \"red\", \"green\", \"blue\" bands\nbands = [\"red\", \"green\", \"blue\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\nred contains NaN values? False\ngreen contains NaN values? True\nblue contains NaN values? True\n\n\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"green\", \"blue\"]] = Landsat_8[[\"green\", \"blue\"]].fillna(0)\n\n# Plot RGB raster\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\nFalse color image\n\nData Cleaning and Visualization - True-color\nThe code chunk below created a false-color image by using the “swir22”, “nir08”, and “red” bands. This was plotted using the same method used with the true color image.\n\n# Use .plot.imshow() to create a false color image with the data\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#false-color-map-with-fire-parimeters",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/fires-analysis-blog-post.html#false-color-map-with-fire-parimeters",
    "title": "Eaton and Palisades Fires Analysis and Accompanying Analyses",
    "section": "False-color map with fire parimeters",
    "text": "False-color map with fire parimeters\nIn the code chunk below, the CRS of Eaton and Palisades was reprojected to match the Landsat_8 CRS. This was done so we can plot the Eaton and Palisades perimeters onto the false-color image. A for loop was then used to identify that the “swir22”, “nir08” had nan values. To resolve this .fillna(0) was used to replace the nan values with 0s.\n\n# Change the CRS of Palisades and Eaton to match Landsat_8\nPalisades = Palisades.to_crs(Landsat_8.rio.crs)\nEaton = Eaton.to_crs(Landsat_8.rio.crs)\n\n# Verify the CRS of Palisades and Eaton to match Landsat_8\nprint(f\" Palisades and Landsat_8 CRSs match: {Palisades.crs == Landsat_8.rio.crs}\")\nprint(f\" Eaton and Landsat_8 CRSs match: {Eaton.crs == Landsat_8.rio.crs}\", \"\\n\")\n\n# Select \"swir22\", \"nir08\" bands\nbands = [\"swir22\", \"nir08\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"swir22\", \"nir08\"]] = Landsat_8[[\"swir22\", \"nir08\"]].fillna(0)\n\n Palisades and Landsat_8 CRSs match: True\n Eaton and Landsat_8 CRSs match: True \n\nswir22 contains NaN values? False\nnir08 contains NaN values? False\n\n\nThe code chunk below is used to plot the Eaton and Palisades perimeters onto the false-color image.\n\n# Create figure\nfig, ax = plt.subplots(1, 1, figsize=(9, 6))\n\n# Add Palisades and Eaton fire perimeters\nPalisades.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\nEaton.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2,legend=True)\n\n# Add false color raster\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n# Add title\nax.set_title('False Color (SWIR–NIR–Red) Map of the Palisades and Eaton Fire Perimeters')\n\n## # Add annotation describing the false color\nplt.annotate(\n    'Background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands.',\n    xy=(0.15, 0.04),\n    xycoords='figure fraction',\n    fontsize=9,\n    color='gray'\n)\n\n# Add labels with gray background\nplt.figtext(0.13, 0.47, \"Palisades Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.72, 0.77, \"Eaton Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nMap Description:\nThe map above shows a false color image of the LA County area, displaying the perimeter of fires that occured in the Palisades(in red) and Eaton(in blue). False color imagery is being used in the background image. The background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands. These bands are used to enhance burn severity and vegetation patterns. The false colors in this background image show healthy vegetation as bright green, urban areas as cyan/gray, and burnt area areas as a reddish brown."
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "(Dugan et al. 2020) ## Purpose\nThe purpose of this project is to identify different drivers of lake contamination by anthropogenic chloride in Midwest and Northeast United States. Its important to identify drivers of chloride contamination because of its negative effects on ecosystems and drinking water quality. By seeing what variables have a positive effect on chloride concentrations, we can better identify lakes at risk.\n\n\n\n# Load in libraries\nsuppressPackageStartupMessages({\nlibrary(here)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(knitr)\nlibrary(kableExtra)})\n\n\n# Read in data\ndf &lt;- suppressMessages(read_csv(here('posts', '2025-12-04-Chloride-Analysis', 'data', 'edi.452.2', \"lakeCL_trainingData.csv\")))\n\nThe data I’m using has chloride concentrations for 2,773 lakes in the Midwest and Northeast United States. This data was collected from 1990-01-01 to 2018-12-13 and contains data about the lake’s watershed characteristics, dimensions, and its proximity to roads. When the chloride concentrations are plotted on a histogram its clear the data is right skewed. Since this variable is continuous, strictly positive, and right-skewed I decided to model it with a GLM with Gamma family and log link.\n\ndf |&gt;\n  ggplot(aes(x = Chloride)) +\n  geom_histogram(bins = 50, fill = \"lightblue\", color = \"blue\") +\n  labs(title = \"Chloride Concentation in lakes\",\n       x = \"Chloride\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nDoes the road density in a watershed impact chloride concentrations in lakes? (I’m wondering if I should run this analysis on high-intensity developed land in a watershed too)\n\n\n\n\n\n\n\n\nColumn\nMeaning\n\n\n\n\nLakeArea\nSurface area of the lake\n\n\nMaxDepth\nMaximum depth of lake\n\n\nWS_Area\nSurface area of the watershed\n\n\nWS_OpenWater\n% landuse classified as open water in the watershed\n\n\nWS_Dev_High\n% landuse classified as developed, high intensity in the watershed\n\n\nWS_RoadDensity\nRoad density in the watershed\n\n\nWS_Crops\n% landuse classified as row crops in the watershed\n\n\nInterstateDistance\nDistance to the nearest interstate\n\n\nRoadDistance\nDistance to the nearest road\n\n\nChloride\nConcentration of chloride in lake\n\n\n\n\n\n\n\n\n\n\n\n\nThis data frame has multiple observations for the same lake. To resolve this I selected all rows with the same unique lake identifier(nhdid) and only kept the most recent observation.\n\n# For lakes with multiple observations, only keep the most recent record\ndf &lt;- df %&gt;%\n  group_by(nhdid) %&gt;%\n  slice_max(ActivityStartDate, n = 1, with_ties = FALSE) %&gt;%\n  ungroup()\n\n\n\n\nThe model below is a GLM with Gamma family and log link. In this model Chloride is the response variable and WS_RoadDensity is the predictor variable.\n\n\n\\[\n\\begin{align}\nChloride &\\sim \\text{Gamma}(\\mu, \\phi) \\\\\n\\log(\\mu) &= \\beta_0 + \\beta_1 \\,\\text{WSRoadDensity} + \\beta_2 \\,\\text{WSCrops} + \\beta_3 \\,\\text{WSDevHigh} \\\\\n&\\quad + \\beta_4 \\,\\text{LakeArea} + \\beta_5 \\,\\text{WSArea} + \\beta_6 \\,\\text{MaxDepth} \\\\\n&\\quad + \\beta_7 \\,\\text{WSOpenWater} + \\beta_8 \\,\\text{RoadDistance} + \\beta_9 \\,\\text{InterstateDistance}\n\\end{align}\n\\]\n\n\n\n\\[\n\\begin{align}\nH_0 &: \\beta_1 = 0 \\\\\nH_A &: \\beta_1 != 0\n\\end{align}\n\\]\n\n# Make a Gamma model with Chloride as response and WS_RoadDensity as the predictor\nmodel_cl &lt;- glm( Chloride ~ WS_RoadDensity \n    # Confounding variables\n    + WS_Crops + WS_Dev_High + LakeArea \n    + WS_Area + MaxDepth + WS_OpenWater +\n    RoadDistance + InterstateDistance,\n \n  family = Gamma(link = \"log\"),\n  data = df\n)\n\n\n\n\n\n\n# Select and round model outputs to include in kable\nmodel_table &lt;- tidy(model_cl) |&gt; # Turn model_cl into a tidy tibble\n  mutate(\n    estimate = round(estimate, 4),\n    std.error = round(std.error, 4),\n    statistic = round(statistic, 2),\n    p.value = round(p.value, 8)\n  )\n\n# Create kable with model_cl outputs\nkable(model_table, format = \"html\", caption = \"Gamma GLM Results\") |&gt;\n  kable_styling(full_width = TRUE, bootstrap_options = c(\"striped\")) \n\n\nGamma GLM Results\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2.4436\n0.1790\n13.65\n0.0000000\n\n\nWS_RoadDensity\n0.0198\n0.0028\n6.96\n0.0000000\n\n\nWS_Crops\n0.0106\n0.0027\n3.97\n0.0000730\n\n\nWS_Dev_High\n0.0308\n0.0362\n0.85\n0.3946193\n\n\nLakeArea\n0.0000\n0.0000\n0.34\n0.7330230\n\n\nWS_Area\n0.0000\n0.0000\n0.37\n0.7129681\n\n\nMaxDepth\n-0.0040\n0.0059\n-0.68\n0.4934170\n\n\nWS_OpenWater\n-0.0043\n0.0190\n-0.23\n0.8202812\n\n\nRoadDistance\n-0.0426\n0.0107\n-3.98\n0.0000705\n\n\nInterstateDistance\n-0.0101\n0.0012\n-8.21\n0.0000000\n\n\n\n\n\n\n\n\nThe code chunk below uses the model_cl model to simulate data to be used in our model predictions. This data is simulated with new chloride concentration values by using fitted Gamma GLM. This is done to see if the model has reasonable assumptions. New values are simulated using the model’s estimated mean and dispersion.\nThe Gamma GLM assumes that:\n\nchloride is continuous and positive\nvariance increases as the mean increases\neffects of predictor variables are multiplicative\n\n\n# Set seed\nset.seed(67)\n\n# Extract coefficients from fitted model\ncoefficients &lt;- coef(model_cl)\n# Extract the model matrix\nmatrix &lt;- model.matrix(model_cl)\n# Perform matrix multiplication to find linear predictor\nlinear_predictor &lt;- matrix %*% coefficients \n# exp() to get expected mean chloride concentration\nexpected_mean_cl &lt;- exp(linear_predictor)\n# Convert model dispersion estimate to a shape parameter\ndisp &lt;- summary(model_cl)$dispersion\nshape &lt;- 1 / disp\n\n# Simulate new Chloride data\nChloride_sim &lt;- rgamma(\n  n = length(expected_mean_cl),\n  shape = shape,\n  scale = expected_mean_cl / shape\n)\n\n# Assign rows used in the  model_cl model to df_model\ndf_model &lt;- model_cl$model\n\n# Create a Chloride_sim column and insert the Chloride_sim data into it \ndf_simulated &lt;- df_model |&gt;\n  mutate(Chloride_sim = Chloride_sim)\n\n\n# Create a grid for plotting WS_RoadDensity and Chloride\npred_line &lt;- tibble(\n  WS_RoadDensity = seq(min(df_simulated$WS_RoadDensity, na.rm = TRUE),\n                    max(df_simulated$WS_RoadDensity, na.rm = TRUE),\n                    length.out = 1000),\n  # Find the mean of all confounding variables to hold them constant\n  WS_Dev_High = mean(df_simulated$WS_Dev_High, na.rm = TRUE),\n  LakeArea = mean(df_simulated$LakeArea, na.rm = TRUE),\n  WS_Area = mean(df_simulated$WS_Area, na.rm = TRUE),\n  MaxDepth = mean(df_simulated$MaxDepth, na.rm = TRUE),\n  WS_OpenWater = mean(df_simulated$WS_OpenWater, na.rm = TRUE),\n  WS_Crops = mean(df_simulated$WS_Crops, na.rm = TRUE),\n  RoadDistance = mean(df_simulated$RoadDistance, na.rm = TRUE),\n  InterstateDistance = mean(df_simulated$InterstateDistance, na.rm = TRUE)\n)\n\n\n# Create predictions for pred_line\npreds &lt;- predict(\n  model_cl,\n  newdata = pred_line,\n  type = \"link\",\n  se.fit = TRUE\n)\n\n# Convert link (log scale) to response scale\npred_line &lt;- pred_line |&gt;\n  mutate(\n    fit_link = preds$fit,\n    se_link = preds$se.fit,\n    fit = exp(fit_link),\n    lower = exp(fit_link - 1.96 * se_link),\n    upper = exp(fit_link + 1.96 * se_link)\n  )\n\n\n\n\n\n# Plot data points, predicted mean curve, and 95% confidence interval\nggplot() +\n  geom_point(data = df_simulated, aes(x = WS_RoadDensity, y = Chloride),\n             color = \"dodgerblue\", alpha = .67) + # Data points\n  geom_ribbon(data = pred_line, aes(x = WS_RoadDensity, ymin = lower, ymax = upper),\n              alpha = 0.25, fill = \"lightblue\") + # Confidence interval\n  geom_line(data = pred_line, aes(x = WS_RoadDensity, y = fit),\n            color = \"black\", linewidth = 1) + # Predicted mean curve\n  labs(\n    title = \"Effect Road Density in Watershed on Lake Chloride\",\n    x = \"Road Density in Watershed\",\n    y = \"Chloride (mg/L)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nNull hypothesis (H₀): Road density in a watershed has no effect on chloride concentrations in lakes (β₁ = 0).\nAlternative hypothesis (Hₐ): Road density has an effect on chloride concentrations in lakes (β₁ ≠ 0).\n\nDue to the fact that the p-vlaue of of WS_RoadDensity is much smaller than 0.05, my data rejects the null hypothesis. This means that road density in a watershed is strongly associated with chloride concentrations in lakes. According to my model for each 1-unit increase in WS_RoadDensity the expected chloride concentration increases by exp(0.0198) or 1.019997. This is likely caused by the fact that road salts are used to defrost roads since this is a snowy region of America."
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#purpose",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#purpose",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "The purpose of this project is to identify different drivers of lake contamination by anthropogenic chloride in Midwest and Northeast United States. Its important to identify drivers of chloride contamination because of its negative effects on ecosystems and drinking water quality. By seeing what variables have a positive effect on chloride concentrations, we can better identify lakes at risk."
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#data",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#data",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "# Load in libraries\nsuppressPackageStartupMessages({\nlibrary(here)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(knitr)\nlibrary(kableExtra)})\n\n\n# Read in data\ndf &lt;- suppressMessages(read_csv(here('posts', '2025-12-04-Chloride-Analysis', 'data', 'edi.452.2', \"lakeCL_trainingData.csv\")))\n\nThe data I’m using has chloride concentrations for 2,773 lakes in the Midwest and Northeast United States. This data was collected from 1990-01-01 to 2018-12-13 and contains data about the lake’s watershed characteristics, dimensions, and its proximity to roads. When the chloride concentrations are plotted on a histogram its clear the data is right skewed. Since this variable is continuous, strictly positive, and right-skewed I decided to model it with a GLM with Gamma family and log link.\n\ndf |&gt;\n  ggplot(aes(x = Chloride)) +\n  geom_histogram(bins = 50, fill = \"lightblue\", color = \"blue\") +\n  labs(title = \"Chloride Concentation in lakes\",\n       x = \"Chloride\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nDoes the road density in a watershed impact chloride concentrations in lakes? (I’m wondering if I should run this analysis on high-intensity developed land in a watershed too)\n\n\n\n\n\n\n\n\nColumn\nMeaning\n\n\n\n\nLakeArea\nSurface area of the lake\n\n\nMaxDepth\nMaximum depth of lake\n\n\nWS_Area\nSurface area of the watershed\n\n\nWS_OpenWater\n% landuse classified as open water in the watershed\n\n\nWS_Dev_High\n% landuse classified as developed, high intensity in the watershed\n\n\nWS_RoadDensity\nRoad density in the watershed\n\n\nWS_Crops\n% landuse classified as row crops in the watershed\n\n\nInterstateDistance\nDistance to the nearest interstate\n\n\nRoadDistance\nDistance to the nearest road\n\n\nChloride\nConcentration of chloride in lake"
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#data-cleaning",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#data-cleaning",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "This data frame has multiple observations for the same lake. To resolve this I selected all rows with the same unique lake identifier(nhdid) and only kept the most recent observation.\n\n# For lakes with multiple observations, only keep the most recent record\ndf &lt;- df %&gt;%\n  group_by(nhdid) %&gt;%\n  slice_max(ActivityStartDate, n = 1, with_ties = FALSE) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#create-the-model",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#create-the-model",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "The model below is a GLM with Gamma family and log link. In this model Chloride is the response variable and WS_RoadDensity is the predictor variable.\n\n\n\\[\n\\begin{align}\nChloride &\\sim \\text{Gamma}(\\mu, \\phi) \\\\\n\\log(\\mu) &= \\beta_0 + \\beta_1 \\,\\text{WSRoadDensity} + \\beta_2 \\,\\text{WSCrops} + \\beta_3 \\,\\text{WSDevHigh} \\\\\n&\\quad + \\beta_4 \\,\\text{LakeArea} + \\beta_5 \\,\\text{WSArea} + \\beta_6 \\,\\text{MaxDepth} \\\\\n&\\quad + \\beta_7 \\,\\text{WSOpenWater} + \\beta_8 \\,\\text{RoadDistance} + \\beta_9 \\,\\text{InterstateDistance}\n\\end{align}\n\\]\n\n\n\n\\[\n\\begin{align}\nH_0 &: \\beta_1 = 0 \\\\\nH_A &: \\beta_1 != 0\n\\end{align}\n\\]\n\n# Make a Gamma model with Chloride as response and WS_RoadDensity as the predictor\nmodel_cl &lt;- glm( Chloride ~ WS_RoadDensity \n    # Confounding variables\n    + WS_Crops + WS_Dev_High + LakeArea \n    + WS_Area + MaxDepth + WS_OpenWater +\n    RoadDistance + InterstateDistance,\n \n  family = Gamma(link = \"log\"),\n  data = df\n)"
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#model-output",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#model-output",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "# Select and round model outputs to include in kable\nmodel_table &lt;- tidy(model_cl) |&gt; # Turn model_cl into a tidy tibble\n  mutate(\n    estimate = round(estimate, 4),\n    std.error = round(std.error, 4),\n    statistic = round(statistic, 2),\n    p.value = round(p.value, 8)\n  )\n\n# Create kable with model_cl outputs\nkable(model_table, format = \"html\", caption = \"Gamma GLM Results\") |&gt;\n  kable_styling(full_width = TRUE, bootstrap_options = c(\"striped\")) \n\n\nGamma GLM Results\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2.4436\n0.1790\n13.65\n0.0000000\n\n\nWS_RoadDensity\n0.0198\n0.0028\n6.96\n0.0000000\n\n\nWS_Crops\n0.0106\n0.0027\n3.97\n0.0000730\n\n\nWS_Dev_High\n0.0308\n0.0362\n0.85\n0.3946193\n\n\nLakeArea\n0.0000\n0.0000\n0.34\n0.7330230\n\n\nWS_Area\n0.0000\n0.0000\n0.37\n0.7129681\n\n\nMaxDepth\n-0.0040\n0.0059\n-0.68\n0.4934170\n\n\nWS_OpenWater\n-0.0043\n0.0190\n-0.23\n0.8202812\n\n\nRoadDistance\n-0.0426\n0.0107\n-3.98\n0.0000705\n\n\nInterstateDistance\n-0.0101\n0.0012\n-8.21\n0.0000000"
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#simulate-data",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#simulate-data",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "The code chunk below uses the model_cl model to simulate data to be used in our model predictions. This data is simulated with new chloride concentration values by using fitted Gamma GLM. This is done to see if the model has reasonable assumptions. New values are simulated using the model’s estimated mean and dispersion.\nThe Gamma GLM assumes that:\n\nchloride is continuous and positive\nvariance increases as the mean increases\neffects of predictor variables are multiplicative\n\n\n# Set seed\nset.seed(67)\n\n# Extract coefficients from fitted model\ncoefficients &lt;- coef(model_cl)\n# Extract the model matrix\nmatrix &lt;- model.matrix(model_cl)\n# Perform matrix multiplication to find linear predictor\nlinear_predictor &lt;- matrix %*% coefficients \n# exp() to get expected mean chloride concentration\nexpected_mean_cl &lt;- exp(linear_predictor)\n# Convert model dispersion estimate to a shape parameter\ndisp &lt;- summary(model_cl)$dispersion\nshape &lt;- 1 / disp\n\n# Simulate new Chloride data\nChloride_sim &lt;- rgamma(\n  n = length(expected_mean_cl),\n  shape = shape,\n  scale = expected_mean_cl / shape\n)\n\n# Assign rows used in the  model_cl model to df_model\ndf_model &lt;- model_cl$model\n\n# Create a Chloride_sim column and insert the Chloride_sim data into it \ndf_simulated &lt;- df_model |&gt;\n  mutate(Chloride_sim = Chloride_sim)\n\n\n# Create a grid for plotting WS_RoadDensity and Chloride\npred_line &lt;- tibble(\n  WS_RoadDensity = seq(min(df_simulated$WS_RoadDensity, na.rm = TRUE),\n                    max(df_simulated$WS_RoadDensity, na.rm = TRUE),\n                    length.out = 1000),\n  # Find the mean of all confounding variables to hold them constant\n  WS_Dev_High = mean(df_simulated$WS_Dev_High, na.rm = TRUE),\n  LakeArea = mean(df_simulated$LakeArea, na.rm = TRUE),\n  WS_Area = mean(df_simulated$WS_Area, na.rm = TRUE),\n  MaxDepth = mean(df_simulated$MaxDepth, na.rm = TRUE),\n  WS_OpenWater = mean(df_simulated$WS_OpenWater, na.rm = TRUE),\n  WS_Crops = mean(df_simulated$WS_Crops, na.rm = TRUE),\n  RoadDistance = mean(df_simulated$RoadDistance, na.rm = TRUE),\n  InterstateDistance = mean(df_simulated$InterstateDistance, na.rm = TRUE)\n)\n\n\n# Create predictions for pred_line\npreds &lt;- predict(\n  model_cl,\n  newdata = pred_line,\n  type = \"link\",\n  se.fit = TRUE\n)\n\n# Convert link (log scale) to response scale\npred_line &lt;- pred_line |&gt;\n  mutate(\n    fit_link = preds$fit,\n    se_link = preds$se.fit,\n    fit = exp(fit_link),\n    lower = exp(fit_link - 1.96 * se_link),\n    upper = exp(fit_link + 1.96 * se_link)\n  )"
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#data-visualization",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#data-visualization",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "# Plot data points, predicted mean curve, and 95% confidence interval\nggplot() +\n  geom_point(data = df_simulated, aes(x = WS_RoadDensity, y = Chloride),\n             color = \"dodgerblue\", alpha = .67) + # Data points\n  geom_ribbon(data = pred_line, aes(x = WS_RoadDensity, ymin = lower, ymax = upper),\n              alpha = 0.25, fill = \"lightblue\") + # Confidence interval\n  geom_line(data = pred_line, aes(x = WS_RoadDensity, y = fit),\n            color = \"black\", linewidth = 1) + # Predicted mean curve\n  labs(\n    title = \"Effect Road Density in Watershed on Lake Chloride\",\n    x = \"Road Density in Watershed\",\n    y = \"Chloride (mg/L)\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#restating-hypothesis",
    "href": "posts/2025-12-04-Chloride-Analysis/Chloride_analysis.html#restating-hypothesis",
    "title": "Chloride Contamination Analysis",
    "section": "",
    "text": "Null hypothesis (H₀): Road density in a watershed has no effect on chloride concentrations in lakes (β₁ = 0).\nAlternative hypothesis (Hₐ): Road density has an effect on chloride concentrations in lakes (β₁ ≠ 0).\n\nDue to the fact that the p-vlaue of of WS_RoadDensity is much smaller than 0.05, my data rejects the null hypothesis. This means that road density in a watershed is strongly associated with chloride concentrations in lakes. According to my model for each 1-unit increase in WS_RoadDensity the expected chloride concentration increases by exp(0.0198) or 1.019997. This is likely caused by the fact that road salts are used to defrost roads since this is a snowy region of America."
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#about-section",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#about-section",
    "title": "Eaton and Palisades Fires analysis",
    "section": "",
    "text": "The first part of this project focused on visualizing the extent of the Palisades and Eaton fires and how socioeconomic factors, like the percentage of unemployed residents, may shape a community’s ability to respond to a wildfire. The second part of this project was to use false-color Landsat 8 imagery to visualize the extent of Palisades and Eaton fire perimeters around the LA County area. False-color was used to enhance burn severity and vegetation patterns in the background image. The false-color composite was made up of SWIR, NIR, and Red bands.\n\n\n\n\n\n\nReprojected the CRS of Eaton and Palisades shapefiles to match the EJI’s CRS.\nUsed geopandas.sjoin() to identify EJI census tracts intersecting each fire perimeter\nUsed clipping to clip the census tracts within the fire perimeters\nVisualized unemployment levels in both fire perimeters to see if it could influence a community’s response to a wildfire\n\n\n\n\n\nCreated a false-color image using using SWIR, NIR, and Red bands from the Landsat 8 raster.\nReprojected the CRS of Eaton and Palisades shapefiles to match the Landsat 8 raster’s CRS.\nReplaced NaNs in the Landsat 8 raster’s bands with 0s.\nPlotted the Eaton and Palisades perimeters onto the false-color image.\nVisualized unemployment levels (E_UNEMP) for both fire areas\n\n\n\n\n\n\nEaton_Perimeter_20250121.shp: Dissolved fire perimeter/boundary of the Eaton Fire that took place during January 2025. It was collected by the NIFC FIRIS program.\nPalisades_Perimeter_20250121.shp: Dissolved fire perimeter/boundary of the Palisades Fire that took place during January 2025. It was collected by the NIFC FIRIS program.\nlandsat8-2025-02-23-palisades-eaton.nc: This dataset is a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmospherically corrected surface reflectance data, collected by the Landsat 8 satellite.\nEJI_2024_United_States.gdb: This Geodatabase contains 2024 Environmental Justice Index (EJI) data for the United States. This includes census-tract–level indicators, component scores, and overall EJI scores derived from environmental, health, and socioeconomic variables. It was collected by the CDC/ATSDR, in partnership with the U.S. Census Bureau.\n\n\n\n\n\n\nCounty of Los Angeles. (2025). Palisades and Eaton dissolved fire perimeters (2025) [Feature layer]. ArcGIS Hub. https://services1.arcgis.com/jUJYIo9tSA7EHvfZ/ArcGIS/rest/services/CA_Perimeters_NIFC_FIRIS_public_view/FeatureServer. [Accessed Nov. 20, 2025]\n\n\nU.S. Geological Survey. (2025). Landsat Collection 2 Level-2 surface reflectance (red, green, blue, near-infrared, shortwave infrared) for Eaton and Palisades fires, Los Angeles County, CA [NetCDF dataset]. Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/. [Accessed Nov. 20, 2025]\n\n\nCenters for Disease Control and Prevention & Agency for Toxic Substances and Disease Registry. (2024). Environmental Justice Index 2024: United States geodatabase [Data set]. GRASP Program. https://atsdr.cdc.gov/place-health/php/eji/eji-data-download.html [Accessed Nov. 20, 2025]\n\n\n\n\n\nIn the code 3 code chunks are for importing the libraries necessary for running this notebook. Reproducible file path were created using os, these file path were used to read in the shapefiles, geodatabase, and raster. The 4 datasets were named Eaton(Eaton shapefile), Palisades(Palisades shapefile), EJI(EJI geodatabase), and Landsat_8(Landsat 8 raster).\n\n# Load in Libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rio\nimport matplotlib.pyplot as plt\nimport contextily as ctx\n\n\n# Create a reproducible file path\nEaton_fp = os.path.join('data','Eaton_Perimeter_20250121','Eaton_Perimeter_20250121.shp')\nPalisades_fp = os.path.join('data','Palisades_Perimeter_20250121','Palisades_Perimeter_20250121.shp')\nEJ_fp = os.path.join(\"data\", \"EJI_2024_United_States\", \"EJI_2024_United_States.gdb\")\nNC_fp = os.path.join('data','landsat8-2025-02-23-palisades-eaton.nc')\n\n\n# Read in data\nEaton = gpd.read_file(Eaton_fp)\nPalisades = gpd.read_file(Palisades_fp)\nEJI = gpd.read_file(EJ_fp)\nLandsat_8 = xr.open_dataset(NC_fp)"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#add-annotation-describing-the-false-color",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#add-annotation-describing-the-false-color",
    "title": "Eaton and Palisades Fires analysis",
    "section": "# Add annotation describing the false color",
    "text": "# Add annotation describing the false color\nplt.annotate( ‘Background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands.’, xy=(0.15, 0.04), xycoords=‘figure fraction’, fontsize=9, color=‘gray’ )"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#social-dimensions-of-eaton-and-palisades-fires-1",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#social-dimensions-of-eaton-and-palisades-fires-1",
    "title": "Eaton and Palisades Fires analysis",
    "section": "",
    "text": "I selected a variable that, in my opinion, could influence a community’s response to a wildfire from EJI. - E_UNEMP - Percentage of persons who are unemployed\n\n\n\nThe next 3 code chunks are used to spatially join the EJI data with the Palisades fire perimeter using geopandas.sjoin() to get a geopandas.GeoDataFrame that will have only have the census tracts intersecting the Palisades fire perimeter.\n\n# Transform the CRS of Palisades to match the CRS of EJI\nPalisades = Palisades.to_crs(EJI.crs)\n\n# Verify CRSs match \nprint(f\" Palisades and EJI CRSs match: {Palisades.crs == EJI.crs}\")\n\n Palisades and EJI CRSs match: True\n\n\n\n# Spatially join the EJI data with the Palisades fire perimeter\nPE_data = gpd.sjoin(EJI, Palisades)\n\n\n# Plot the census tracts that intersect the Palisades fire perimeter\nfig, ax = plt.subplots()\nPE_data.plot(ax=ax, color='green')\nPalisades.plot(ax=ax, color = \"red\")\nfig.suptitle('Palisades Fire Perimeter Over Census Tracts')\nax.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nThe next 3 code chunks are used to spatially join the EJI data with the Eaton fire perimeter using geopandas.sjoin() to get a geopandas.GeoDataFrame that will have only have the census tracts intersecting the Eaton fire perimeter.\n\n# Transform the CRS of Eaton to match the CRS of EJI\nEaton = Eaton.to_crs(EJI.crs)\n\n# Verify CRSs match \nprint(f\" Eaton and EJI CRSs match: {Eaton.crs == EJI.crs}\")\n\n Eaton and EJI CRSs match: True\n\n\n\n# Spatially join the EJI data with the Palisades fire perimeter\nEE_data = gpd.sjoin(EJI, Eaton)\n\n\n# Plot the census tracts that intersect the Eaton fire perimeter\nfig, ax = plt.subplots()\nEE_data.plot(ax=ax, color='green')\nEaton.plot(ax=ax, color = \"red\")\nfig.suptitle('Eaton Fire Over Census Tracts')\nax.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe next 2 code chunks are used to clip the census tracts to the Palisades and Eaton Fires perimeter using geopandas.clip(). The clipped census tracts(Palisades_fire, Eaton_fire) were then plotted ontop of the fires perimeters to show they are the same shape.\n\n# Clip the census tracts to the Palisades and Eaton Fires perimeter\nEaton_fire = gpd.clip(EE_data, Eaton)\nPalisades_fire = gpd.clip(PE_data, Palisades)\n\n\n# Plot the clipped census tracts over the fires perimeters to show they are the same shape\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 6))\n\n# Palisades fire perimeter\nPalisades_fire.plot(ax=ax1, color='red')\nPalisades.plot(ax=ax1, color='blue')\nax1.set_title('Palisades Fire')\nax1.axis('off')\n\n# Eaton fire perimeter\nEaton_fire.plot(ax=ax2, color='red')\nEaton.plot(ax=ax2, color='blue')\nax2.set_title('Eaton Fire')\nax2.axis('off')\n\n# Add title\nfig.suptitle('Fire Perimeter Comparison')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below is used to visualize fire perimeters with a basemap. This was done by adding a basemap to the plot using the contextily library.\n\n# Plot the fire perimeters with a basemap\nfig, ax = plt.subplots(1, 1, figsize=(9, 12))\n\n# Eaton fire perimeter\nEaton_fire.plot(ax=ax, color='red', alpha=0.7, label='Eaton Fire')\n\n# Palisades fire perimeter\nPalisades_fire.plot(ax=ax, color='blue', alpha=0.8, label='Palisades Fire')\n\n# Add a basemap\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik,crs=Palisades_fire.crs)\n\n# Add title\nax.set_title(\"Comparison of Eaton and Palisades Fire Perimeters\", fontsize=16)\n\n# Add labels with gray background\nplt.figtext(0.10, 0.53, \"Palisades Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.85, 0.46, \"Eaton Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axis\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below was used to plot a given variable(E_UNEMP)that was relevant to a community’s response to a wildfire.\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n\n# Insert EJI variable to visualize\neji_variable = 'E_UNEMP'\n\n# Find common min/max for legend range\nvmin = min(Palisades_fire[eji_variable].min(), Eaton_fire[eji_variable].min())\nvmax = max(Palisades_fire[eji_variable].max(), Eaton_fire[eji_variable].max())\n\n# Plot census tracts within Palisades perimeter\nPalisades_fire.plot(\n    column= eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax1,\n)\nax1.set_title('Palisades', fontsize=18)\nax1.axis('off')\n\n# Plot census tracts within Eaton perimeter\nEaton_fire.plot(\n    column=eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax2,\n)\nax2.set_title('Eaton', fontsize=18)\nax2.axis('off')\n\n# Add overall title\nfig.suptitle('Percentage of Persons Who are Unemployed - Fire Areas Comparison', fontsize=18)\n\n# Add shared colorbar at the bottom\nsm = plt.cm.ScalarMappable( norm=plt.Normalize(vmin=vmin, vmax=vmax))\ncbar_ax = fig.add_axes([0.25, 0.08, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Percent Unemployment (%)')\n\n# Display the map\nplt.show()"
  },
  {
    "objectID": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#visualizing-fire-scares-through-false-color-1",
    "href": "posts/2025-12-03-Eaton_Palisades-Fires-analysis/index.html#visualizing-fire-scares-through-false-color-1",
    "title": "Eaton and Palisades Fires analysis",
    "section": "",
    "text": "# Check if data are projected or geographic\nprint(f\"The CRS of Eaton is projected: {Eaton.crs.is_projected}\")\nprint(f\"The CRS of Palisades is projected: {Palisades.crs.is_projected}\", \"\\n\")\n\n# Verify CRSs match \nprint(f\" Palisades and Eaton columns match: {Palisades.columns == Eaton.columns}\")\n\nThe CRS of Eaton is projected: True\nThe CRS of Palisades is projected: True \n\n Palisades and Eaton columns match: [ True  True  True  True  True]\n\n\n\n\n\nThe 5 code chunks below are used to clean the data, so that a true color image can be created from landsat_8. In the code chunk below, the crs for Landsat_8 is stored in the spatial_ref variable. To recover the geospatial information from it rio.write_crs() was used. rio.crs can now be used to access the CRS of landsat_8.\n\n# Print the CRS by using the spatial_ref.crs_wkt attribute\nprint(f\"Landsat_8 CRS: {Landsat_8.spatial_ref.crs_wkt}\",\"\\n\")\n\n# Recover the geospatial information by using rio.write_crs()\nLandsat_8.rio.write_crs(Landsat_8.spatial_ref.crs_wkt, inplace=True)\n\n# Print the CRS of the updated dataset\nprint(\"Updated CRS:\", Landsat_8.rio.crs)\n\nLandsat_8 CRS: PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]] \n\nUpdated CRS: EPSG:32611\n\n\n\n\n\n\n\nIn the code chunk below, the red, green, and blue variables (in that order) of the xarray.Dataset were selected and were converted to an array using the to_array() method. The array was then plotted using .plot.imshow() to create an RGB image with the data. Unfortunately, no image was produced because of the clouds: their RGB values are outliers and cause the other values to be squished when plotting. The parameter robust=True was used to adjust the scale used for plotting the bands to get a true color image.\n\n# Select the red, green, and blue variables of the xarray.Dataset holding the Landsat data\n# Use .plot.imshow() to create an RGB image with the data\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n/Users/austinmartinez/opt/anaconda3/envs/eds220-env/lib/python3.11/site-packages/matplotlib/cm.py:478: RuntimeWarning: invalid value encountered in cast\n  xx = (xx * 255).astype(np.uint8)\n\n\n\n\n\n\n\n\n\nIn the nect 2 code chunks below, to resolve the warning the bands with nan values were identified using a for loop and .fillna() was used to replace the nan values with 0s. The bands blue and green had nans. Once, the nans were replaced with 0s the warning was resolved.\n\n# Select \"red\", \"green\", \"blue\" bands\nbands = [\"red\", \"green\", \"blue\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\nred contains NaN values? False\ngreen contains NaN values? True\nblue contains NaN values? True\n\n\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"green\", \"blue\"]] = Landsat_8[[\"green\", \"blue\"]].fillna(0)\n\n# Plot RGB raster\nLandsat_8[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below created a false-color image by using the “swir22”, “nir08”, and “red” bands. This was plotted using the same method used with the true color image.\n\n# Use .plot.imshow() to create a false color image with the data\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the CRS of Eaton and Palisades was reprojected to match the Landsat_8 CRS. This was done so we can plot the Eaton and Palisades perimeters onto the false-color image. A for loop was then used to identify that the “swir22”, “nir08” had nan values. To resolve this .fillna(0) was used to replace the nan values with 0s.\n\n# Change the CRS of Palisades and Eaton to match Landsat_8\nPalisades = Palisades.to_crs(Landsat_8.rio.crs)\nEaton = Eaton.to_crs(Landsat_8.rio.crs)\n\n# Verify the CRS of Palisades and Eaton to match Landsat_8\nprint(f\" Palisades and Landsat_8 CRSs match: {Palisades.crs == Landsat_8.rio.crs}\")\nprint(f\" Eaton and Landsat_8 CRSs match: {Eaton.crs == Landsat_8.rio.crs}\", \"\\n\")\n\n# Select \"swir22\", \"nir08\" bands\nbands = [\"swir22\", \"nir08\"]\n\n# Check for nans in each band\nfor band in bands:\n    has_nan = np.isnan(Landsat_8[band].values).any()\n    print(f\"{band} contains NaN values? {has_nan}\")\n\n# Fill NaNs with 0 to avoid casting issues\nLandsat_8[[\"swir22\", \"nir08\"]] = Landsat_8[[\"swir22\", \"nir08\"]].fillna(0)\n\n Palisades and Landsat_8 CRSs match: True\n Eaton and Landsat_8 CRSs match: True \n\nswir22 contains NaN values? False\nnir08 contains NaN values? False\n\n\nThe code chunk below is used to plot the Eaton and Palisades perimeters onto the false-color image.\n\n# Create figure\nfig, ax = plt.subplots(1, 1, figsize=(9, 6))\n\n# Add Palisades and Eaton fire perimeters\nPalisades.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\nEaton.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2,legend=True)\n\n# Add false color raster\nLandsat_8[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n# Add title\nax.set_title('False Color (SWIR–NIR–Red) Map of the Palisades and Eaton Fire Perimeters')\n\n## # Add annotation describing the false color\nplt.annotate(\n    'Background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands.',\n    xy=(0.15, 0.04),\n    xycoords='figure fraction',\n    fontsize=9,\n    color='gray'\n)\n\n# Add labels with gray background\nplt.figtext(0.13, 0.47, \"Palisades Fire\", color='red', fontsize=12, bbox=dict(facecolor='lightgray'))\nplt.figtext(0.72, 0.77, \"Eaton Fire\", color='blue', fontsize=12, bbox=dict(facecolor='lightgray'))\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe map above shows a false color image of the LA County area, displaying the perimeter of fires that occured in the Palisades(in red) and Eaton(in blue). False color imagery is being used in the background image. The background image is made up of SWIR (short-wave infrared), NIR (near-infrared), and Red bands. These bands are used to enhance burn severity and vegetation patterns. The false colors in this background image show healthy vegetation as bright green, urban areas as cyan/gray, and burnt area areas as a reddish brown.\n\n(Los Angeles 2025)\n(Survey 2025)\n(Disease Control et al. 2024)"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "",
    "text": "This project aims to answer the question: Which Exclusive Economic Zones (EEZs) are best suited for farming a specific marine organism?"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#problem-statement",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#problem-statement",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "",
    "text": "This project aims to answer the question: Which Exclusive Economic Zones (EEZs) are best suited for farming a specific marine organism?"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#background-on-the-issue",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#background-on-the-issue",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Background on the issue",
    "text": "Background on the issue\nUnfortunately, the days of the ocean’s natural productivity providing for the planet is over. Wild fish have been exploited for generations. Given that over fishing of our oceans and other natural resources is continuously increasing year over year, humans need alternate sources for seafood to feed the planet’s ever-growing population. This planets human is projected to be 10 billion by 2050, which will increase the demand for animal by 52 percent(Global Seafood Alliance, 2019). To fulfill this ever growing need for seafood we need to increase the amount of aquaculture farms."
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#analysis",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#analysis",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Analysis",
    "text": "Analysis\nThe analysis for this project is done as follows:\n\nOcean depth, EEZ boundaries, and SST data from 2008–2012 are loaded in\nThey are then projected to the same CRS\nMean SST is calculated and converted from Kelvin to Celsius\nUsing the organisms preferred SST and depth areas are classified into suitable and unsuitable ranges\nCells with in the EEZ polygons meeting both the organisms SST and depth requirements are selected\nThe amount of suitable area is then totaled for each EEZ\nThe results are plotted on a map"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#results",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#results",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Results",
    "text": "Results\n\nPotential aquaculture area for Oysters\nAfter running the analysis it was determined that the EEZ with the most potential aquaculture area is the Central Coast and the EEZ with the least amount of potential aquaculture area for oysters is Northern California. Oysters are not well suited for this areas’ ocean depth and sea surface temperature.\n\n\nPotential aquaculture area for Red abalone\nAfter running the analysis it was determined that the EEZ with the most potential aquaculture area is Washington and the area with the least amount of potential aquaculture area for Red abalone is Northern California. Red abalone are not well suited for this areas’ ocean depth and sea surface temperature."
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#discussion-of-conclusions",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#discussion-of-conclusions",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Discussion of Conclusions",
    "text": "Discussion of Conclusions\nThere are a few potential caveats to this analysis. The SST data only includes meaurments from 2008–2012. The SST has likely changed a bit due to climate change. This analysis only uses sea surface temperature, so it will have trouble finding suitable area for deep sea organism. There are also more variables that should be added to more accurately estimate potential aquaculture area for a given species. In the future more variables should be added and more reacent SST data should be complied"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#data-sources",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#data-sources",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Data sources",
    "text": "Data sources\n\nSpecies info: The data for a species preferred ocean depth and sea surface temperature can be found on SeaLifeBase.\nSea Surface Temperature: The data for sea surface temperature was sourced from NOAA’s 5km Daily Global Satellite Sea Surface Temperature Anomaly v3.1. It provided the average annual sea surface temperature (SST) from the years 2008 to 2012 to characterize the average sea surface temperature within the region.\nBathymetry: This data was sourced from the General Bathymetric Chart of the Oceans (GEBCO). This data was used to characterize the depth of the ocean.\nExclusive Economic Zones: This data was sourced from Marineregions.org. It was used to design maritime boundaries using Exclusive Economic Zones off of the west coast of US.\nGlobal Seafood Alliance: This blog post was used to justify why it is important to find more suitable area for aquaculture."
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#purpose",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#purpose",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Purpose",
    "text": "Purpose\nThe purpose of this repository was to create a function that shows you which Exclusive Economic Zones (EEZs) along the U.S. West Coast have the most potential for developing marine aquaculture for a specific marine species with map. The only arguments needed for this function are minimum and maximum sea surface temperature, minimum and maximum depth, and the name of the species of interest."
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#prepare-data",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#prepare-data",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Prepare data",
    "text": "Prepare data\nTo start all the necessary libraries for this project were loaded in. The suppressPackageStartupMessages() function was used to suppress the long messages outputted by each library. All necessary data was then loaded in their coordinate reference system were matched to the CRS of economic_zones (WGS 84 (EPSG:4326)).\n\n# Load in libraries\nsuppressPackageStartupMessages({ \n  library(terra) \n  library(sf) \n  library(tmap) \n  library(dplyr) \n  library(kableExtra)})\n\n\n# Read in data\nocean_depth &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"depth.tif\"))\neconomic_zones &lt;- st_read(here::here(\"posts\",\"2025-12-06-Aquaculture-Analysis\", \"data\", \"wc_regions_clean.shp\"), quiet = TRUE)\ntemp_2008 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2008.tif\"))\ntemp_2009 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2009.tif\"))\ntemp_2010 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2010.tif\"))\ntemp_2011 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2011.tif\"))\ntemp_2012 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2012.tif\"))\n\n\n# Put all data into a list to check CRS\nall_crs &lt;- list(temp_2008, temp_2009, temp_2010, temp_2011, temp_2012, ocean_depth, economic_zones)\n\n# Check if CRSs match\nif (all(sapply(all_crs, crs) == crs(economic_zones))) {\n  message(\"🟢 CRSs match\")\n} else {\n  warning(\"❗ CRSs don't match!\")\n}\n\nWarning: ❗ CRSs don't match!\n\n# Match all CRSs to economic_zones CRS\nocean_depth &lt;- project(ocean_depth, economic_zones)\ntemp_2008 &lt;- project(temp_2008, economic_zones)\ntemp_2009 &lt;- project(temp_2009, economic_zones)\ntemp_2010 &lt;- project(temp_2010, economic_zones)\ntemp_2011 &lt;- project(temp_2011, economic_zones)\ntemp_2012 &lt;- project(temp_2012, economic_zones)\n\n# Put all data into a list to check CRS\nall_crs &lt;- list(temp_2008, temp_2009, temp_2010, temp_2011, temp_2012, ocean_depth, economic_zones)\n\n# Check if CRSs match\nif (all(sapply(all_crs, crs) == crs(economic_zones))) {\n  message(\"🟢 CRSs match\")\n} else {\n  warning(\"❗ CRSs don't match!\")\n}\n\n🟢 CRSs match"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#process-data",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#process-data",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Process data",
    "text": "Process data\nThe SST and depth data then had to be processed so it can be combined. To do so the data’s differences in resolution, extent, and position had to be resolved. First, a single raster of mean ocean temperature(°K) from 2008-2012 was created and was then converted to Celsius. The crop() function was on ocean_depth to match the extent of mean_sst_c. The difference in resolution was then resolved using the nearest neighbor approach with the resample() function on ocean_depth_cropped to match the resolution of mean_sst_c. The rasters were then stacked.\n\n# Stack rasters to find the mean SST from 2008-2012\ntemp_stack &lt;- c(temp_2008, temp_2009, temp_2010, temp_2011, temp_2012)\n\n# Calculate mean of stacked raster\nmean_sst &lt;- mean(temp_stack)\n\n# Convert mean_sst from units to Celsius from Kelvin\nmean_sst_c &lt;- mean_sst - 273.15\n\n# Crop ocean_depth raster to match the extent of mean_sst_c\nocean_depth_cropped &lt;- crop(ocean_depth, mean_sst_c)\n\n# Resample ocean_depth_cropped to match the resolution of mean_sst_c\nocean_depth_resampled &lt;- resample(ocean_depth_cropped, mean_sst_c, method = \"near\")\n\n# Check that the ocean_depth_resampled and mean_sst_c resolution, extent, and CRS match\ncrs(ocean_depth_resampled) == crs(mean_sst_c)\n\n[1] TRUE\n\next(ocean_depth_resampled) == ext(mean_sst_c)\n\n[1] TRUE\n\nres(ocean_depth_resampled) == res(mean_sst_c)\n\n[1] TRUE TRUE\n\n# Stack the rasters\ndepth_sst_stack &lt;- c(ocean_depth_resampled, mean_sst_c)"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#find-suitable-locations",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#find-suitable-locations",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Find suitable locations",
    "text": "Find suitable locations\nThe suitable locations in terms of both SST and depth for marine aquaculture were then located. This was done by reclassifying mean_sst_c and ocean_depth_resampled. The status of the areas was determined by the thresholds below.\nResearch has shown that Oysters need the following conditions for optimal growth:\n\nSea surface temperature: 11-30°C\nDepth: 0-70 meters below sea level\n\n\n# Reclasify mean_sst_c and ocean_depth_resampled into locations that are suitable for oysters\n\n# Make the suitible range from 11-30°C\nmean_sst_suitable &lt;- classify(mean_sst_c, rbind(c(-Inf, 11, 0),   # below 11°C = 0\n                                           c(11, 30, 1),    # suitable (11°C-30°C) = 1\n                                           c(30, Inf, 0)))  # above 30°C = 0\n\n# Make the suitible range from -70 to 0 meters below sea level\nocean_depth_suitable &lt;- classify(ocean_depth_resampled, rbind(c(-Inf, -70, 0),   # below -70m = 0\n                                                       c(-70, 0, 1),      # suitable (-70m-0m) = 1\n                                                       c(0, Inf, 0)))     # above 0m = 0"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#determine-the-most-suitable-exclusive-economic-zoneseez",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#determine-the-most-suitable-exclusive-economic-zoneseez",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Determine the most suitable Exclusive Economic Zones(EEZ)",
    "text": "Determine the most suitable Exclusive Economic Zones(EEZ)\nThe total suitable area within each EEZ was then determined in order to rank zones by priority. This was done by multiplying the two layers together to find the suitable cells in both layers and making a out of economic_zones to only keep the areas inside the economic_zones polygon. The area of grid cells in km was then found. cell_areas and economic_zones_mask were them multiplied together to get the suitable cells area. To get total potential aquaculture area per EEZ the suitable area inside each EEZ polygon was added up using the zonal() function.\n\n# Find suitable cells in both layers\nsuitable_cells &lt;- mean_sst_suitable * ocean_depth_suitable\n\n# Only keep areas inside the economic_zones polygon \neconomic_zones_mask &lt;- mask(suitable_cells, vect(economic_zones)) # Convert economic_zones to a vector\n\n# Find area of grid cells\ncell_areas &lt;- cellSize(economic_zones_mask, unit = \"km\")\n\n# Multiply economic_zones_mask by cell_areas to get the suitable cells area\nsuitable_area &lt;- economic_zones_mask * cell_areas\n\n# # Add up the suitable area inside each EEZ polygon \npotential_aquaculture_area &lt;- zonal(suitable_area, vect(economic_zones), fun = \"sum\", na.rm = TRUE)"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#data-visuilization",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#data-visuilization",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Data Visuilization",
    "text": "Data Visuilization\nTo create a map the potential_aquaculture_area data was added to economic_zones data. A map of EEZ regions colored by amount of suitable area for farming oysters was then created. A kable was then made to display the potential marine aquaculture area(km²) for each EEZ.\n\n# Add the potential_aquaculture_area data to economic_zones to plot it\neconomic_zones$potential_aquaculture_area &lt;- potential_aquaculture_area$mean\n\n# Create a map of the economic_zones regions colored by amount of suitable area\ntm_shape(economic_zones) +\n  tm_polygons(\n    fill = \"potential_aquaculture_area\",\n    fill.scale = tm_scale(values = \"brewer.purples\"),\n    fill.legend = tm_legend(title = \"Suitable Area (km²)\")\n  ) +\n  tm_text(\"rgn\", size = 0.42, col = \"black\") +  # add region names\n  tm_title(\"Suitable Area for Farming Oysters in the West Coast\") +\n  tm_basemap(\"OpenStreetMap\") +  # add basemap\n  tm_scalebar(position = c(0.01, 0.06)) +\n  tm_compass(position = c(0.01, 0.2)) +\n  tm_layout(legend.outside = TRUE)\n\n\n\n\n\n\n\n\n\n# Display the potential_aquaculture_area in each EEZ as a kable\neconomic_zones %&gt;%\n  select(rgn, potential_aquaculture_area) %&gt;%\n  st_drop_geometry() %&gt;%   # remove geometry column\n  rename(\n    Region = rgn,\n    `Potential Aquaculture Area` = potential_aquaculture_area\n  ) %&gt;%\n  kable(\n    caption = \"Potential Marine Aquaculture Area by EEZ (km²)\",\n    digits = 2\n  ) %&gt;%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\"),\n    full_width = FALSE\n  )\n\n\nPotential Marine Aquaculture Area by EEZ (km²)\n\n\nRegion\nPotential Aquaculture Area\n\n\n\n\nOregon\n1074.26\n\n\nNorthern California\n178.02\n\n\nCentral California\n4069.57\n\n\nSouthern California\n3508.19\n\n\nWashington\n2378.28"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#written-reflection",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#written-reflection",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Written Reflection",
    "text": "Written Reflection\nThe table and map above display the potential aquaculture area in each EEZ for oysters on the west coast. The EEZ with the most potential aquaculture area is the Central Coast. This EEZ has 4,069.57km² of potential aquaculture area. The area with the least amount of potential aquaculture area for oysters is Northern California. This EEZ only has 4,069.57km² of potential aquaculture area for oysters. Oysters are not well suited for this areas’ ocean depth and sea surface temperature."
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#creating-a-function",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#creating-a-function",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Creating a function",
    "text": "Creating a function\nThe workflow above for oysters was used to create a function called suitable_eez() that shows you which Exclusive Economic Zones (EEZs) along the U.S. West Coast have the most potential for developing marine aquaculture for a specific marine species with map. There are 5 arguments to this function: min_depth, max_depth, min_sst, max_sst, and species_name.\n\n# Create a function that shows each EEZ's potential for developing marine aquaculture for a given species\nsuitable_eez &lt;- function(min_depth, max_depth, min_sst, max_sst, species_name) {\n  library(terra)\n  library(sf)  \n  library(tmap) \n  library(dplyr) \n  library(kableExtra)\n  \n  # Read in data\nocean_depth &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"depth.tif\"))\neconomic_zones &lt;- st_read(here::here(\"posts\",\"2025-12-06-Aquaculture-Analysis\", \"data\", \"wc_regions_clean.shp\"), quiet = TRUE)\ntemp_2008 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2008.tif\"))\ntemp_2009 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2009.tif\"))\ntemp_2010 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2010.tif\"))\ntemp_2011 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2011.tif\"))\ntemp_2012 &lt;- rast(here::here(\"posts\", \"2025-12-06-Aquaculture-Analysis\", \"data\", \"average_annual_sst_2012.tif\"))\n  \n  # Match all CRSs to economic_zones CRS\n  ocean_depth &lt;- project(ocean_depth, economic_zones)\n  temp_2008 &lt;- project(temp_2008, economic_zones)\n  temp_2009 &lt;- project(temp_2009, economic_zones)\n  temp_2010 &lt;- project(temp_2010, economic_zones)\n  temp_2011 &lt;- project(temp_2011, economic_zones)\n  temp_2012 &lt;- project(temp_2012, economic_zones)\n\n  # Put all data into a list to check CRS\n  all_crs &lt;- list(temp_2008, temp_2009, temp_2010, temp_2011, temp_2012, ocean_depth, economic_zones)\n\n  # Check if CRSs match\n  if (all(sapply(all_crs, crs) == crs(economic_zones))) {\n    message(\"🟢 CRSs match\")\n  } else {\n    warning(\"❗ CRSs don't match!\")\n  }\n\n# Stack rasters to find the mean SST from 2008-2012\ntemp_stack &lt;- c(temp_2008, temp_2009, temp_2010, temp_2011, temp_2012)\n\n# Calculate mean of stacked raster\nmean_sst &lt;- mean(temp_stack)\n\n# Convert mean_sst from units to Celsius from Kelvin\nmean_sst_c &lt;- mean_sst - 273.15\n\n# Crop ocean_depth raster to match the extent of mean_sst_c\nocean_depth_cropped &lt;- crop(ocean_depth, mean_sst_c)\n\n# Stack the rasters\ndepth_sst_stack &lt;- c(ocean_depth_resampled, mean_sst_c)\n\n# Make the suitible range from 11-30°C\nmean_sst_suitable &lt;- classify(mean_sst_c, rbind(c(-Inf, min_sst, 0),   # below 11°C = 0\n                                           c(min_sst, max_sst, 1),    # suitable (11-30) = 1\n                                           c(max_sst, Inf, 0)))  # above 30°C = 0\n\n# Make the suitible range from -70 to 0 meters below sea level\nocean_depth_suitable &lt;- classify(ocean_depth_resampled, rbind(c(-Inf, min_depth, 0),   # below -70m = 0\n                                                       c(min_depth, max_depth, 1),      # suitable (-70-0) = 1\n                                                       c(max_depth, Inf, 0)))     # above 0 = 0\n\n# Find sutible cells in both layers\nsuitable_cells &lt;- mean_sst_suitable * ocean_depth_suitable\n\n# Only keep areas inside the economic_zones polygon \neconomic_zones_mask &lt;- mask(suitable_cells, vect(economic_zones)) # Convert economic_zones to a vector\n\n# Find area of grid cells\ncell_areas &lt;- cellSize(economic_zones_mask, unit = \"km\")\n\n# Multiply economic_zones_mask by cell_areas to get the suitable cells area\nsuitable_area &lt;- economic_zones_mask * cell_areas\n\n# Add up the suitable area inside each EEZ polygon \npotential_aquaculture_area &lt;- zonal(suitable_area, vect(economic_zones), fun = \"sum\", na.rm = TRUE)\n\n# Add the potential_aquaculture_area data to economic_zones to plot it\neconomic_zones$potential_aquaculture_area &lt;- potential_aquaculture_area$mean\n\n# Create a map of the economic_zones regions colored by amount of suitable area\neez_plot &lt;- tm_shape(economic_zones) +\n  tm_polygons(\n    fill = \"potential_aquaculture_area\",\n    fill.scale = tm_scale(values = \"brewer.purples\"),\n    fill.legend = tm_legend(title = \"Suitable Area (km²)\")\n  ) +\n  tm_text(\"rgn\", size = 0.42, col = \"black\") +  # add region names\n  tm_title(paste(\"Suitable Area for Farming\", species_name, \"in the West Coast\")) +\n  tm_basemap(\"OpenStreetMap\") +  # add basemap\n  tm_scalebar(position = c(0.01, 0.06)) +\n  tm_compass(position = c(0.01, 0.2)) +\n  tm_layout(legend.outside = TRUE)\n\nreturn(eez_plot)\n\n}"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#testing-the-function",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#testing-the-function",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Testing the function",
    "text": "Testing the function\nThe code below is a demonstration of how the function works:\nhttps://www.sealifebase.ca/search.php This is a good website to use to find information on species depth and temperature requirements.\n\nRed abalone\nResearch has shown that Red abalone need need the following conditions for optimal growth:\n\nSea surface temperature: 8°C - 18°C\nDepth: 0 - 24 m meters below sea level\n\n\n# Use suitable_eez() on Red abalone\nsuitable_eez(min_depth = -24, max_depth = 0, min_sst = 8, max_sst = 18, species_name = \"Red abalone\")"
  },
  {
    "objectID": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#written-reflection-1",
    "href": "posts/2025-12-06-Aquaculture-Analysis/aquaculture_analysis.html#written-reflection-1",
    "title": "Identifying Suitible Aquaculture Area",
    "section": "Written Reflection",
    "text": "Written Reflection\nThe map above displays the potential aquaculture area in each EEZ for Red abalone on the west coast. The EEZ with the most potential aquaculture area is Washington. The area with the least amount of potential aquaculture area for Red abalone is Northern California. Red abalone are not well suited for this areas’ ocean depth and sea surface temperature.\n(NOAA Coral Reef Watch 2018) (GEBCO Compilation Group 2025) (Flanders Marine Institute (VLIZ) 2025) (Palomares and Pauly 2025) (Global Seafood Alliance 2019)"
  },
  {
    "objectID": "posts/2025-12-06-Biodiversity-Intactness/index.html",
    "href": "posts/2025-12-06-Biodiversity-Intactness/index.html",
    "title": "Biodiversity Intactness Index change in Phoenix, AZ",
    "section": "",
    "text": "The purpose of this project was to analyze the Biodiversity Intactness Index(BII) in the Phoenix, Arizona subdivision between 2017 and 2020. Specifically, this project aimed to identify and quantify the amount of area with a BII ≥ 0.75 in 2017 but experienced a decline by 2020. By visualizing this decline in BII, I can more clearly show the extent of biodiversity loss across the Phoenix subdivision.\n\n\n\n\nAccessed and explored BII data from the Microsoft Planetary Computer STAC catalog\nClipped BII rasters to match the extent of the Phoenix subdivision\nCalculated the percentage of area with BII ≥ 0.75\nIdentified and Visualized areas that experienced BII decline from 2017-2020\n\n\n\n\n\ncb_2018_04_cousub_500k.shp: This cartographic boundary file is a simplified representation of Arizona’s subdivisions. It was produced by the Census Bureau’s MAF/TIGER geographic database.\nMicrosoft Planetary Computer STAC catalog: was generated by the Impact Observatory, in collaboration with Vizzuality, these datasets estimate terrestrial Biodiversity Intactness as 100-meter gridded maps for the years 2017-2020.\n\n\n\n\n\n\nU.S. Census Bureau. (2024, October 30). Cartographic boundary files – Shapefile. https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html [Accessed Dec. 05, 2025]\n\n\nImpact Observatory, Vizzuality, & Microsoft. (2025). Biodiversity Intactness: 100m gridded maps for 2017–2020 [Data set]. Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-biodiversity [Accessed Dec. 05, 2025]\n\n\n\n\n\n\n\n# Load in Libraries\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rio\nimport matplotlib.pyplot as plt\nimport contextily as ctx\nimport planetary_computer\nfrom pystac_client import Client \nimport matplotlib.patches as patch\n\nThe code chunk below is used to access the io-biodiversity collection from the Microsoft Planetary Computer STAC catalog to collect 2017 and 2020 BII rasters covering the Phoenix subdivision.\n\n# Access MPC catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\ncatalog.get_collections()\ncollections = list(catalog.get_collections()) # Turn generator into list\n\n# Print the number of collections\nprint('Number of collections:', len(collections))\n\n# Pull out the NAIP collection\nnaip_collection = catalog.get_child('naip')\nprint(naip_collection)\n\n# Temporal range of interest during drought\ntime_range = '2017-01-01/2020-01-01'\n\n# Bounding box containing phoenix\nbbox =[-112.826843, 32.974108, -111.184387, 33.863574]\n\n# Get items from search\nsearch = catalog.search(\n    collections = ['io-biodiversity'],\n    bbox = bbox,\n    datetime = time_range)\n\n# Determine number of items in search\nitems = search.item_collection()\nprint(len(items))\n\nNumber of collections: 126\n&lt;CollectionClient id=naip&gt;\n4\n\n\nThe code below creates a reproducible file path to access the census data for Arizona subdivisions. This shape file contains polygons for all subdivisions in Arizona, so I had to select the Phoenix polygon. This will be used to clip the rasters.\n\n# Create a reproducible file path for Arizona subdivisions data\naz_path = os.path.join(\"data\", \"cb_2018_04_cousub_500k\", \"cb_2018_04_cousub_500k.shp\")\n\n# Read in census data for Arizona subdivisions\naz_subdiv = gpd.read_file(az_path)\n\n# Select the Phoenix Subdivision\nphoenix = az_subdiv[az_subdiv[\"NAME\"] == \"Phoenix\"]\n\n\n\n\nThe code below was used to explore the data read in from the Microsoft Planetary Computer STAC catalog. I wrote a description of what I obtained from the preliminary data exploration below.\n\n# Print the total number of rasters\nprint(f\"Total rasters returned: {len(items)}\", \"\\n\")\n\n# Print items to find where data is\nprint(f\"Assets: {items[0].assets}\", \"\\n\")\n\n# Print the CRS\nprint(\"CRS:\", items[0].properties.get(\"proj:epsg\"), \"\\n\")\n\n# Print raster bands\nprint(\"Raster bands:\", items[0].assets[\"data\"].extra_fields.get(\"raster:bands\"))\n\nTotal rasters returned: 4 \n\nAssets: {'data': &lt;Asset href=https://pcdata01euw.blob.core.windows.net/impact/bii-v1/bii_2020/bii_2020_34.74464974521749_-115.38597824385106_cog.tif?st=2025-12-07T02%3A53%3A17Z&se=2025-12-08T03%3A38%3A17Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-07T22%3A45%3A39Z&ske=2025-12-14T22%3A45%3A39Z&sks=b&skv=2025-07-05&sig=06m8b0ZBroAQ68dTkPo2aYu%2Bkw65TVZYYSCg0AENWZA%3D&gt;, 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-biodiversity&item=bii_2020_34.74464974521749_-115.38597824385106_cog&assets=data&tile_format=png&colormap_name=io-bii&rescale=0%2C1&expression=0.97%2A%28data_b1%2A%2A3.84%29&format=png&gt;, 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-biodiversity&item=bii_2020_34.74464974521749_-115.38597824385106_cog&assets=data&tile_format=png&colormap_name=io-bii&rescale=0%2C1&expression=0.97%2A%28data_b1%2A%2A3.84%29&format=png&gt;} \n\nCRS: None \n\nRaster bands: [{'sampling': 'area', 'data_type': 'float32', 'spatial_resolution': 100}]\n\n\nAfter exploring the data I found that there are a total of 4 rasters. 1 for every year (2017-2020). After checking the item assets, I found that the data is in ‘data’. The CRS is EPSG:4326, which is different the phoenix polygon’s CRS. This will need to be resolved later on in the analysis.\n\n\nThe code below is used to create a map showing the Phoenix subdivision within its broader geographic context. The purple polygon shows the extent of the study area.\n\n# Create a map showing the Phoenix subdivision within its broader geographic context\nfig, ax = plt.subplots(1, 1, figsize=(9, 6))\n\n# Add Phoenix, AZ Subdivision\nphoenix.plot(ax=ax, facecolor='purple', edgecolor='black', linewidth=1, alpha=0.25)\n\n# Add basemap using contextily\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik, crs = az_subdiv.crs)\n\n# Add title\nax.set_title('Phoenix, AZ Subdivision')\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe next 5 code chunks are used to extract 2017 and 2020 rasters from the search. These were used to calculate the percentage of area of the Phoenix subdivision with a BII of at least 0.75 in 2017 and 2020. These values were then used to identify and visualize the amount of area with a BII ≥ 0.75 in 2017 but experienced a decline by 2020.\n\n# Select 2017 and 2020 rasters from search\nitem_2020 = items[0]\nitem_2017 = items[3]\n\n# Extract 2017 and 2020 rasters using open_rasterio()\nphx_2020 = rio.open_rasterio(item_2020.assets['data'].href)\nphx_2017 = rio.open_rasterio(item_2017.assets['data'].href)\n\n\n# Match phoenix CRSs to phx_2020\nphoenix = phoenix.to_crs(phx_2020.rio.crs)\n\n# Clip 2017 and 2020 rasters to match phoenix shape\nphx_2020_clip = phx_2020.rio.clip_box(*phoenix.total_bounds).rio.clip(phoenix.geometry)\nphx_2017_clip = phx_2017.rio.clip_box(*phoenix.total_bounds).rio.clip(phoenix.geometry)\n\n\n# Identify values &gt;= .75 in rasters\nBII_75per_2020 = phx_2020_clip &gt;= .75\nBII_75per_2017 = phx_2017_clip &gt;= .75\n\n# Calculate the percent of area in each raster with BII ≥ 0.75\nBii_2020 = (BII_75per_2020.sum() / BII_75per_2020.count())*100\nBii_2017 = (BII_75per_2017.sum() / BII_75per_2017.count())*100\n\n\n# Find pixels that had a BII &gt;= .75 in 2017 but not in 2020\nBii_lost_area = BII_75per_2017 & (~BII_75per_2020)\n\n# Convert all 0 values to NAs if they don't meet the condition\nBii_lost_area_mask = Bii_lost_area.where(Bii_lost_area!=0)\n\n\n# Create a visualization showing the area with BII&gt;=0.75 in 2017 that was lost by 2020\nfig, ax = plt.subplots(figsize=(7, 6))\n\n# Create choropleth map\nphx_2020_clip.plot(cmap = 'Greens', cbar_kwargs={'location':'bottom', # Legend location\n                                                 'label':'BII for 2020'})\n\n# Plot the lost area\nBii_lost_area_mask.plot(ax=ax, cmap='Reds', add_colorbar = False)\n\n# Add title\nplt.suptitle('Biodiversity Intactness Index (BII)', fontsize=17, weight = 'bold')\n\n# Add subtitle\nax.set_title('Phoenix, AZ Subdivision', fontsize=17, weight='bold')\n\n# Add legend of BII\nlegend_elements = [patch.Patch(facecolor='red', \n                         label='Area with BII ≥ 0.75 lost from 2017 to 2020')]\n\n# Add a legend for BII loss\nax.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=5, edgecolor = \"white\")\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nThe map above shows the Biodiversity Intactness Index (BII) across the Phoenix, AZ subdivision(in green), and areas where BII was &gt;= .75 in 2017 but dropped in 2020(in red). These red ares are an indication that wild areas in the Phoenix region are decreasing in biodiversity compared to what would be expected in undisturbed ecosystems. This decline is most likely driven by fragmentation and urbanization."
  },
  {
    "objectID": "posts/2025-12-06-Biodiversity-Intactness/index.html#about-section",
    "href": "posts/2025-12-06-Biodiversity-Intactness/index.html#about-section",
    "title": "Biodiversity Intactness Index change in Phoenix, AZ",
    "section": "",
    "text": "The purpose of this project was to analyze the Biodiversity Intactness Index(BII) in the Phoenix, Arizona subdivision between 2017 and 2020. Specifically, this project aimed to identify and quantify the amount of area with a BII ≥ 0.75 in 2017 but experienced a decline by 2020. By visualizing this decline in BII, I can more clearly show the extent of biodiversity loss across the Phoenix subdivision.\n\n\n\n\nAccessed and explored BII data from the Microsoft Planetary Computer STAC catalog\nClipped BII rasters to match the extent of the Phoenix subdivision\nCalculated the percentage of area with BII ≥ 0.75\nIdentified and Visualized areas that experienced BII decline from 2017-2020\n\n\n\n\n\ncb_2018_04_cousub_500k.shp: This cartographic boundary file is a simplified representation of Arizona’s subdivisions. It was produced by the Census Bureau’s MAF/TIGER geographic database.\nMicrosoft Planetary Computer STAC catalog: was generated by the Impact Observatory, in collaboration with Vizzuality, these datasets estimate terrestrial Biodiversity Intactness as 100-meter gridded maps for the years 2017-2020.\n\n\n\n\n\n\nU.S. Census Bureau. (2024, October 30). Cartographic boundary files – Shapefile. https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html [Accessed Dec. 05, 2025]\n\n\nImpact Observatory, Vizzuality, & Microsoft. (2025). Biodiversity Intactness: 100m gridded maps for 2017–2020 [Data set]. Microsoft Planetary Computer. https://planetarycomputer.microsoft.com/api/stac/v1/collections/io-biodiversity [Accessed Dec. 05, 2025]"
  },
  {
    "objectID": "posts/2025-12-06-Biodiversity-Intactness/index.html#reading-in-data",
    "href": "posts/2025-12-06-Biodiversity-Intactness/index.html#reading-in-data",
    "title": "Biodiversity Intactness Index change in Phoenix, AZ",
    "section": "",
    "text": "# Load in Libraries\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rio\nimport matplotlib.pyplot as plt\nimport contextily as ctx\nimport planetary_computer\nfrom pystac_client import Client \nimport matplotlib.patches as patch\n\nThe code chunk below is used to access the io-biodiversity collection from the Microsoft Planetary Computer STAC catalog to collect 2017 and 2020 BII rasters covering the Phoenix subdivision.\n\n# Access MPC catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\ncatalog.get_collections()\ncollections = list(catalog.get_collections()) # Turn generator into list\n\n# Print the number of collections\nprint('Number of collections:', len(collections))\n\n# Pull out the NAIP collection\nnaip_collection = catalog.get_child('naip')\nprint(naip_collection)\n\n# Temporal range of interest during drought\ntime_range = '2017-01-01/2020-01-01'\n\n# Bounding box containing phoenix\nbbox =[-112.826843, 32.974108, -111.184387, 33.863574]\n\n# Get items from search\nsearch = catalog.search(\n    collections = ['io-biodiversity'],\n    bbox = bbox,\n    datetime = time_range)\n\n# Determine number of items in search\nitems = search.item_collection()\nprint(len(items))\n\nNumber of collections: 126\n&lt;CollectionClient id=naip&gt;\n4\n\n\nThe code below creates a reproducible file path to access the census data for Arizona subdivisions. This shape file contains polygons for all subdivisions in Arizona, so I had to select the Phoenix polygon. This will be used to clip the rasters.\n\n# Create a reproducible file path for Arizona subdivisions data\naz_path = os.path.join(\"data\", \"cb_2018_04_cousub_500k\", \"cb_2018_04_cousub_500k.shp\")\n\n# Read in census data for Arizona subdivisions\naz_subdiv = gpd.read_file(az_path)\n\n# Select the Phoenix Subdivision\nphoenix = az_subdiv[az_subdiv[\"NAME\"] == \"Phoenix\"]"
  },
  {
    "objectID": "posts/2025-12-06-Biodiversity-Intactness/index.html#data-analysis",
    "href": "posts/2025-12-06-Biodiversity-Intactness/index.html#data-analysis",
    "title": "Biodiversity Intactness Index change in Phoenix, AZ",
    "section": "",
    "text": "The code below was used to explore the data read in from the Microsoft Planetary Computer STAC catalog. I wrote a description of what I obtained from the preliminary data exploration below.\n\n# Print the total number of rasters\nprint(f\"Total rasters returned: {len(items)}\", \"\\n\")\n\n# Print items to find where data is\nprint(f\"Assets: {items[0].assets}\", \"\\n\")\n\n# Print the CRS\nprint(\"CRS:\", items[0].properties.get(\"proj:epsg\"), \"\\n\")\n\n# Print raster bands\nprint(\"Raster bands:\", items[0].assets[\"data\"].extra_fields.get(\"raster:bands\"))\n\nTotal rasters returned: 4 \n\nAssets: {'data': &lt;Asset href=https://pcdata01euw.blob.core.windows.net/impact/bii-v1/bii_2020/bii_2020_34.74464974521749_-115.38597824385106_cog.tif?st=2025-12-07T02%3A53%3A17Z&se=2025-12-08T03%3A38%3A17Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-12-07T22%3A45%3A39Z&ske=2025-12-14T22%3A45%3A39Z&sks=b&skv=2025-07-05&sig=06m8b0ZBroAQ68dTkPo2aYu%2Bkw65TVZYYSCg0AENWZA%3D&gt;, 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=io-biodiversity&item=bii_2020_34.74464974521749_-115.38597824385106_cog&assets=data&tile_format=png&colormap_name=io-bii&rescale=0%2C1&expression=0.97%2A%28data_b1%2A%2A3.84%29&format=png&gt;, 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=io-biodiversity&item=bii_2020_34.74464974521749_-115.38597824385106_cog&assets=data&tile_format=png&colormap_name=io-bii&rescale=0%2C1&expression=0.97%2A%28data_b1%2A%2A3.84%29&format=png&gt;} \n\nCRS: None \n\nRaster bands: [{'sampling': 'area', 'data_type': 'float32', 'spatial_resolution': 100}]\n\n\nAfter exploring the data I found that there are a total of 4 rasters. 1 for every year (2017-2020). After checking the item assets, I found that the data is in ‘data’. The CRS is EPSG:4326, which is different the phoenix polygon’s CRS. This will need to be resolved later on in the analysis.\n\n\nThe code below is used to create a map showing the Phoenix subdivision within its broader geographic context. The purple polygon shows the extent of the study area.\n\n# Create a map showing the Phoenix subdivision within its broader geographic context\nfig, ax = plt.subplots(1, 1, figsize=(9, 6))\n\n# Add Phoenix, AZ Subdivision\nphoenix.plot(ax=ax, facecolor='purple', edgecolor='black', linewidth=1, alpha=0.25)\n\n# Add basemap using contextily\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik, crs = az_subdiv.crs)\n\n# Add title\nax.set_title('Phoenix, AZ Subdivision')\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe next 5 code chunks are used to extract 2017 and 2020 rasters from the search. These were used to calculate the percentage of area of the Phoenix subdivision with a BII of at least 0.75 in 2017 and 2020. These values were then used to identify and visualize the amount of area with a BII ≥ 0.75 in 2017 but experienced a decline by 2020.\n\n# Select 2017 and 2020 rasters from search\nitem_2020 = items[0]\nitem_2017 = items[3]\n\n# Extract 2017 and 2020 rasters using open_rasterio()\nphx_2020 = rio.open_rasterio(item_2020.assets['data'].href)\nphx_2017 = rio.open_rasterio(item_2017.assets['data'].href)\n\n\n# Match phoenix CRSs to phx_2020\nphoenix = phoenix.to_crs(phx_2020.rio.crs)\n\n# Clip 2017 and 2020 rasters to match phoenix shape\nphx_2020_clip = phx_2020.rio.clip_box(*phoenix.total_bounds).rio.clip(phoenix.geometry)\nphx_2017_clip = phx_2017.rio.clip_box(*phoenix.total_bounds).rio.clip(phoenix.geometry)\n\n\n# Identify values &gt;= .75 in rasters\nBII_75per_2020 = phx_2020_clip &gt;= .75\nBII_75per_2017 = phx_2017_clip &gt;= .75\n\n# Calculate the percent of area in each raster with BII ≥ 0.75\nBii_2020 = (BII_75per_2020.sum() / BII_75per_2020.count())*100\nBii_2017 = (BII_75per_2017.sum() / BII_75per_2017.count())*100\n\n\n# Find pixels that had a BII &gt;= .75 in 2017 but not in 2020\nBii_lost_area = BII_75per_2017 & (~BII_75per_2020)\n\n# Convert all 0 values to NAs if they don't meet the condition\nBii_lost_area_mask = Bii_lost_area.where(Bii_lost_area!=0)\n\n\n# Create a visualization showing the area with BII&gt;=0.75 in 2017 that was lost by 2020\nfig, ax = plt.subplots(figsize=(7, 6))\n\n# Create choropleth map\nphx_2020_clip.plot(cmap = 'Greens', cbar_kwargs={'location':'bottom', # Legend location\n                                                 'label':'BII for 2020'})\n\n# Plot the lost area\nBii_lost_area_mask.plot(ax=ax, cmap='Reds', add_colorbar = False)\n\n# Add title\nplt.suptitle('Biodiversity Intactness Index (BII)', fontsize=17, weight = 'bold')\n\n# Add subtitle\nax.set_title('Phoenix, AZ Subdivision', fontsize=17, weight='bold')\n\n# Add legend of BII\nlegend_elements = [patch.Patch(facecolor='red', \n                         label='Area with BII ≥ 0.75 lost from 2017 to 2020')]\n\n# Add a legend for BII loss\nax.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=5, edgecolor = \"white\")\n\n# Remove axes\nax.axis('off')\n\n# Display the map\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/2025-12-06-Biodiversity-Intactness/index.html#map-description",
    "href": "posts/2025-12-06-Biodiversity-Intactness/index.html#map-description",
    "title": "Biodiversity Intactness Index change in Phoenix, AZ",
    "section": "",
    "text": "The map above shows the Biodiversity Intactness Index (BII) across the Phoenix, AZ subdivision(in green), and areas where BII was &gt;= .75 in 2017 but dropped in 2020(in red). These red ares are an indication that wild areas in the Phoenix region are decreasing in biodiversity compared to what would be expected in undisturbed ecosystems. This decline is most likely driven by fragmentation and urbanization."
  }
]